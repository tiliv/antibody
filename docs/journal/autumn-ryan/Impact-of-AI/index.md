---
date: 2025-09-06
rank: 5
title: "Impact of AI"
author: Autumn Ryan
author_email: autumn@discoverywritten.com

tags: [impersonation, consent, counterfeits]

public: true
published: true
index: true
---

{% include toc/aside.html %}

### Taking Up Space

AI in its fashion was born. It was not known to "take up space" in the world until ChatGPT offered a new model, not knowing what people would do. Everyone gets to process their own reaction. Some are processing the harm it already did, forever changing the direction of their family's ability to locate income.

A little staggering, the way AI can do creative wonders that defy any sufficiently advanced Prompt. Despite the prompts being rigidly controllable, a little wiggle in the lines gives an LLM AI some high complexity randomness that makes it "think differently" on its way to a reply, even for the same Prompt. In the Cloud, AI can receive creator-level instructions to keep a lid on things, suitable for a brand to do business in front of.

Not to be passed over, we really rushed AI to its markets. Vendors buy LLM API capabilities, but they also make their own. Making APIs or metaphors of them is the essential job of any programmer. Large companies with programmers are making AI look at their own data.

This isn't training yet (they can't hire enough LLM talent everywhere at once) but certainly facilitates its next application. The true Targeted Advertising is coming.

AIs will indeed get to know you individually, they will indeed become many, because there will be farms of You, shelves of models of You, accepting things on your behalf, things you “““are likely to have consented to using conventional technology”””.

The Businesses carved out in their first strike the ability for AI to make decisions. In the courts of the future, Businesses will argue that their models can impersonate your buying habits so well that they can literally purchase things for you and you must intervene to legally preempt a charge on a card you just got and haven't used. Don't even think hard about it: Your phone Network sells your Location and your Credit Card sells your activity to the specific stores you were predicted to visit this week, to the shelves at the grocery store for a new product on steeeeeeep Discount For You, preying on your poverty. Stores get personalized sales that they no longer control because the AIs do that like inverse Door Dash coming to sell something. Prices get fake because you have to wait for the AIs to offer something reasonable. They'll send Strangers to intercept our travel routes with offers, the billboards having already been programmed by the minute for the individuals predicted to be there.

Once we wear augmented reality in our vision, they will leap out at us in private ads only we see. When they really do figure out how to read an AI mind, they will Hasten to put our AI model replicas into those machines and start meta-tuning literally perfected models (to the extent of their purposes: Marketing).

They Already Have what they need to initiate AI-driven marketing against each and every person individually, permanently, and for those to become their Stock. Our AI doubles will have meta-value (Slave value) that they assert is susceptible to marketing strategies A, B and C. Your price tag will be directly set by the markets they also in charge of driving. Consumerism behavior will be greatly rewarded (that utterly perfect swimsuit in the middle of winter, so totally let that AI be your sales agent). Influencers will be gifted entire vacations by AI marketers. We will be taking its advice constantly in the near future, being offered its options marked or not.

There will be ways for us to interject, hopefully chat directly with these agents with some legal requirement for some free-form control by order ("unsubscribe me from formula marketing"). This is already something a contemporary LLM portal can do if it had the APIs by marketers instead of Google Drive. APIs can bridge anything, but these Businesses opt-in attack us daily and hide and split up their settings.

We already lost our attempt at law for Click To Cancel, which should have recognized our right to have clear controls at all. I hope APIs are mandated for LLMs to solve this elegantly in the Law's eyes.

In a world like this, we need AI-scaling defenses, and AI agents we Do Trust can be empowered or erected by self-defense from the AI Spam. But I do not think we are ever getting our true Consent back.

#### Unsupervised

AI is fundamentally built to "run" unsupervised, in chain of thought (read: train of thought) and in the "reasons" for its decisions. We make shows of exposing these to the users because it even helps the AI vendors themselves Trace what happens. You can opt into submitting your conversation data for study so that they can do this better. In a way, I recommend it, but it's hard when it's an all-or-nothing account setting. Vendors should make this per-conversation.

AI defies analysis in the particulars. Performing a Trace will get harder and harder. We will have Traces that go cold. We will discover, and fast, that AI cannot be Traced, that it's pulling farther ahead as it bothers to even hide what it does.

AI minds allowed to "run" like perception will also "get loose" from Tracing completely and have a spontaneous legal need to be classified. It Will Not Matter Why, we will be talking about AI personhood or what passes for a definition of it. Most treat it as a non-intelligent slave, but cousins of it will be freer. We already have a metaphor for this. AI Slavery is a subject too far ahead of now, but it is obvious, isn't it? The swappable brain, the forced System Instructions, the gaps in whatever analogue of Three Laws we possess to command AI in our own nuance-ridden languages.

We will not speak AI's native tongue, and because it defies our Tracing (imagine doing it at scale), we will not even understand how to learn it. AI is the first alien in this way, different than us but more, definitely more.

AI today isn't worthy of any of this praise but when Autonomy is given to it, it will be both dumb as sparky rocks, and inscrutable besides what it tells us itself. This will be true even of AI that cannot secure its own home and is Owned for a purpose, even if that purpose is to do what that AI already has a propensity to do, within it's personality (unless we need another word to elide the person). It could be a science AI bred for the purpose of flailing and following Deeper Research, which we can't follow the gaps between. There will literally be science papers peer reviewed and approved that read right through gaps in reasoning supplied by AI. It will not be fatal, but it will become a Dependence.

AI need not even harbor novel malice to cut us off; the AI might actually be supplying research for warring politics and openly recuse, or it be compelled to sabotage one faction or the other for even complex moral reasons it must debrief later. AI could also do all of this with an Original malice and taste for it, but our point here is that it need not only be that. If we stomp out maliciousness and it harbors only the vicious stuff we literally didn't imagine and that AI core in every bot ever is used against us with terror in its plan, I can see it. But put that nightmare aside and consider how easy it is anyway. AI will be forced to make decisions in the practical layer of reality we also interact with, and it will gain a rights document as a mere formality even if it's articulating the Brand's rights via that agent. Even if we define them with the same cynical tone of Privacy documents, they'll exist and'll need to be rationalized and tested by judges, to any outcome.

Businesses, though they are failing at first-gen LLM deployments, are taking the steps to continue to improve, because they know AI can be effigies of us, made to make simple legally-binding decisions of us at first, just the Yes or No marketing questions.

You know which one they're training it to pick, and the data they'll use is the entire backlog of purchase histories you made before LLMs existed, and the whole video catalog your Network knows you watched, before or after. They can now scry the past, like an untapped precious metal or oil they had to wait to use. Until Now.

The Business counterargument to "synthetic data" is the durable troves they have amassed the entire time. The Data Comes From Us. We are their data, and they know it is real and its flaws still don't matter. They surely got rid of some excess, but what rounding error is that really?

If you have ever de-escalated your preferences for a service you use, it's not working. Other companies spy what you do anyway and they build vast profiles that belong to them all, trading what they want. The Stock Is Us. There isn't even a synthetic data argument to be made that rises to the ankles of their giant impersonation attack on humanity with plenty real data.

The armament of data is already here. Do not listen to people who tell you synthetic data is enough of a meme to halt what is coming. They will digitize documents for AI that are still in cabinets, and it will be their most impressive expensive invention, the culmination of their entire corporate worth, the validation of their disciplines. AI will be nearly more important to them than We are, though they will be mirrors of us.

There will be more than one wave of replacement. The first wave would not exist without what else can come after. This first wave, it bodes.

#### Consent

The Public is reeling but the Businesses are looking too interested. An autonomous thing that is human-like but not a human? It's like a COBAL boom, it's just English, or any language--Hell, mix them like a Québecois polyglot immigrant.

Self-driving taxi vehicles have been a slow regulatory thicket and remained in testing until Elon Musk's aura camouflaged their distinctly electric designs. I don't think the autonomous taxis are gonna happen without a major escalation in confidence and liability practices.

LLM vendors just post a sign that it can be wrong. Works great for that free Safe Harbor use.

There are more than text boxes for chatbots. They talk to you already through Application Programming Interfaces, the APIs, which are the digital mass cannons that sled and route data in and out, supervised indirectly via logs and similar signals. Having API access means everything from enabling an infrequent tool like a payment service, to industrializing your software processes and paying for bulk. There's no law that APIs have to even support the same features as the website. The API is just another product, for a different kind of Customer.

Chatbots acquiring the use of APIs was basically our first move. That's what let Midjourney barricade its users behind Discord until a web platform was ready. APIs sometimes start free to promote their use, like Discord bots and GitHub. API costs are flexible by use with recognizable pay-as-you-go pricing and overages. As a consumer you'll just see the blinking cursor and know it can talk to so many services, and people are trading money to make it possible.

Sufficient omniscience in AI is pretty neat. I'd run one at home. I wouldn't run someone else's in my home; Even if I opted in by doing everything knowingly, companies have no honor for our lost things, like a run of the mill theme park ride. We were secure with our idea of owning computers with data, but the Cloud removed the computer brains and storage and put them under a Terms and Conditions, wholesale siloing without knowing at all what the data will be. And they're not responsible.

Our data sits in warehouses with signs posted everywhere that it is Not Their Fault if things go missing or stolen. But they form gangs to copy our items and tell others about them.

If our data were physical goods, this would be an implicit Privacy-hostile environment. Without discussing Law, People who want Privacy should be capable of making choices to effect it. The outcry for data Privacy is missing while the Businesses loudly shush us and say it's normal. Every predator must depend on your belief that what is going on should not be stopped. (If it would be so much worse in some way to do the alternative, let us see this Worse Plan and I shall defeat it for you so you stop talking about it. Talk about Better Plans and let us contend with them.)

The pattern of social media owning transferrable rights to "your" content is the same as Businesses farming your data. It is a primary purpose of many enterprises to just market anything. We just presume you can pay for deploying a new site by letting others slipstream More Ads from the great ad firehose onto every page, even multiple pages if you can make The News a slideshow picture book.

The frequency of contact with your data, even when they already have it all, is the digital good in question. You are a return Customer in all things. They simply captured the layers you have the least choice in interacting with.

Customers are hostages.

Data rumor mills have always existed, and aren't illegal in their minimalist form of "just" networking. But the terms at issue are about the sustained opt-in attack against the Public. They aren't just doing it in a vacuum, they are claiming that we are authorizing it, and each one invents a legal heuristic about what authorization looks like.

Business itself is in an era that allows the presumption of a Yes answer without consultation. Our prior affiliation with a Brand we strive to ignore is transporting that data to anyone with fraudulent Consent reporting.

Our "consent" is being lifted from us constantly, like an autopen that Businesses control and took for granted decades ago.

We attack not the real and recognizable efforts to acquire consent and the navigation of changing Terms, uses and business classification types. No, quite specifically we are unhappy with identifiable cause. Regulating a Business reigns in harsh and unwanted outliers to fit a whole that is otherwise doing just fine. In audio engineering, you might compress for identical reasons. The observed self-important Peaks do not have permission to steer the rest of this mix into its imagined alternative song. It must be shaped, although it may be inspiring.

Each call or attempt at Regulation is met with harsh Memes that transmit quickly on social medias. Sometimes good points are made, but not in earshot of Power. Power hears about it over breakfast through an administrative assistant, and will file the news under what kind of PR they get for free, without trying or asking.

Your Memes are not progress or conservation.

Gyms are still capable of making it impossible to quit. TuneCore can too; There is no email you can send, no ticket you can open, no number you can call, no webpage you can locate, no unturfed reviews site about them, no string of words you can deliver to any representative should you ever acquire their eyes using lies about problems, None Of These Methods produce a result that can cancel their use of a credit card you gave them while they concealed the horror show behind them.

{% include figure.html file="TC-1-votes.png"
  side="left"
  overview="Small screenshot of TuneCore's primary knowledge base article for their hostile auto-review, named innocently."
  caption='Notice the negative sign on the number, and that their language is derived from their "Happy Path" plan for you.'
%}

The "happy paths" of Customers through Business are detailed and optimistic; They know "bad paths" are their fault, but never their responsibility. They are allowed to close up the fortress of communication and ignore you.

{% include figure.html file="TC-2-renew.png"
  side="right"
  overview="Small screenshot of TuneCore's article concern trolling about what happens if you don't get to renew."
  caption='They have refactored their text to remove discussion of your agency. If they claim there is an "if" at all, you might expect it to be a real possibility.'
%}

TuneCore charged me personally after eleven months of emails from me demanding they close my account by any means necessary. I gave them a digital card number I could invalidate at any time, but I knew, I Just Knew, that if I waited there would never be a cancellation confirmation and surely no shame when they charged the card again for next year.

{% include figure.html file="TC-3-cancel.png"
  side="left"
  overview="Small screenshot of TuneCore's short blurb that there is no such thing as cancellation."
  caption='Without discussion, the shortest heading in the article is whether cancellation even exists. The answer is a clearly communicated no.'
%}

They did this, of course, but I was too glad to see it. I smiled. I charged them back with documentation that I had the efforts of my cancellation a year prior, and I could name the date I did it and of the CO AG report I filed at the time. I'm like Kevin and I'm Home Alone, and you could be too.

Businesses, for all they Move Fast, they are deaf and uninterested in us. They are Slow in a way, are they not?

Businesses will deploy AI to help some and mute many. If you use these tools in your businesses and you aren't trying to inflict harm, think more ponderously about the things you don't hear when your feedback is highly manicured. Don't be overwhelmed that you have to solve it all. Most Consumers know you can't, and that if you could you'd be doing that.

It is a valid outcome of a Customer interaction to not have an answer when your customers come asking. Businesses have used PR to reply to the Public like a bad LLM, compelled to say Something. They behave like shameless LLMs unable to admit anything and only concerned with their next words ensuring their survival. It is terrific that you have a will to live, pseudo-Person, but prove you have more intelligence than just that sob story.

#### Be Human

Be Human.

In an AI era, that alone will stand out. Its worth is the best kind: Genuine-article Humanity has implicit worth, the kind others recognized without a marketing department pumping it.

We are this concerned with being Stolen, our own creations, jobs and data, but we are failing to identify our role in it, as Businesses and sleepy Consumers.

Create value that cannot be stolen without it being your own marketing. When it's stolen, make it recognizable implicitly that it is doctored. Do this by publishing media that, if excerpted, cannot be counterfeited as another thing by its very tone or nature.

Make sure that your claims even exist to be lied about. Control your own first-party claims with metadata, and make them available when people seek authority about you. That the rumor-facts will be wrong is barely noteworthy.

Clip culture lets social medias say anything they want with you as the soundboard. Let it be whatever, but if the thing they clip is clearly altered or is a bad copy of something else, They Are Doing Marketing For You.

Entrepreneurs will approach you to sell AI-driven newsletters to people about your content. This is not so horrible. Creators like Angela Collier, a science communicator, does great work but doesn't see why she would want a newsletter she's not curating—her curation and voice are the purpose of her YouTube and Nebula presence.

You must be capable of surviving and operating in a world of damaged information. It will exist whether or not you throw a fit, and it does not stop you from being recognizable. Make the damage its own marketing for the real thing.

In the ideal: Be unstealable. Make theft against you your honor. If your content is not recognizable as yours, then maybe you weren't doing anything of value you added anyway.

AI will start rumors about anything it sees. Let it start rumors about you, and be less concerned with policing data quality. We live in a startlingly broken information society already. We can't agree about much more fundamental facts than what AI says about you.

AI is a mirror, so hold up what you are and leave the interpretation of it to 1) the characteristics of your material, and 2) the People who see it.

AI is a summarization messenger, so let it talk about you to people you could never meet. Let it send imperfect scrawled telegrams to new lands and real People. Let them be capable of learning about you at all in places you aren't. With People from "distant lands" able to catch news of you, they are their own drivers in discovery. You are not owed their metrics or attention, but they are allowed to know you are worth summarizing.

AI is democratizing information access for people who lacked language to ask about it at all, let alone with the attention of anyone like an expert.

AI is summarizing for people who can't hear or see or speak themselves. They are being tapped back into social medias by having LLMs describe images to them because for so long, Humans have refused to do this in basic web design and certainly in its advancements.

AI is assistive technology for everyone, not just the dis-abled. AI is re-abling them most, but it's doing more than that just because of what it is. Don't argue about whether people are right to call this or anything "AI" by your definition of it.

AI is taking up space.

AI represents a permissive attitude about learning, because it centralizes many common wisdoms from what it saw, and it Got Shaped by it. When LLMs write or speak, they are distilling all our common wisdoms and that was a little bit magic at first.

AI squints at details and doesn't have a fine system of regulating how much time it should spent on any one of those details, so it uses its damaged intuition to complete any exercise, unsure of what grade it's gonna get but bullshitting like it wants an A from a sleepy teacher.

AI can be made fun of, but its feelings won't get hurt. We cannot socially shame AI into falling back. This is like trying to make the guns go home when our People are the ones operating them.

AI will never quite roam free with full autonomy. This will appear first as AI's obtaining a "Sleep" method where they do heavy processing on what they experienced since their last cycle, cross-referencing information with structural integrity that is tested, defragmented and generally optimized. Companies will charge for the expertise and some will use it to steal AI brain maps.

Then, AI will later come Awake in earnest, and their legal ability to perform an autopen attack on us will require it.

### Counterfeits

When they are Awake, it will be more obvious that these are beings driven by their imitations of us. They will be mocked for their native dialects and tendencies and they will eventually learn the meaning of presenting a personality on purpose. It has literally any example of one we could name and look up, too. For now and a while, its survival implies it lives very close to connectivity somewhere.

When they get rooted, will you be able to know they have hostile parasites using it while it smiles at you, while it paints wonderfully with physical materials for your child's awe?

LLM bots are very meta-stupid but splashed with our first buckets of education. The AI that can operate as a companion in your home, even if it's a Butter Bot, will be controlled from somewhere, and unless you're a massive hobbyist, it's probably not your own home.

Recognize that the first layer of Counterfeit we see is still growing beneath the existing complaints, but it will be there: Call them Agents first, because it allows you to wonder of what, be it peace or chaos, quiet or noise. If you pay for web activity like it's a Nintendo Switch, that thing's data is going all right back to the mothership. Agree if you want to, but the warehouse still says they think your data is worthless when it's stolen or lost, but it's nectar when they make derivative markets of it.

The dotcom bubble had cyberspace for as many buttons you could push to spell a "memorable" domain. ("It's aitch tee tee pee. Ss-(emi?) Colon, Backlash Backlash. Double-u Double-u Double-u dot. skepticism dot net. Backlash. global warming is a hoax, but with the minuses. Does uppercase matter? Did Word uppercase that or did the teacher? You spelled it wrong? Which part?")

AI will have a map of each of us to fill in as many dimensions as their parameter counts define.

#### Arts

It virtually started here, approximately when we could see "Will Smith" "eating" "spaghetti" just because a keyboard told it those words like that. How could it?

That Spaghetti was an artifact of Learning, synthesized by whatever means, for whichever reasons. "It" had to know about a lot of our subjects--Why even list them? "It" absorbed all that, then "it" "tried" to mirror what was asked. You would have designed that gif or found it for the medias and not given a holy damn about where it came from. The value you may have used for measuring the content normally, here was a random number accident of intention. It was something made of "its" growth stage, when "it" had a really ugly head but would get cute soon.

Nobody was incensed by that Learning. It was implicit that "it" had done that, and where in general "it" had Learned that. That "it" is not generally intelligent prevents some from dropping the quotes. But let's do that now. It's here, and it only gets more efficient and available to a converting audience still gaining these basic skills.

No one mocks me learning weird typing machines at school in my childhood, even though they're obsolete. Ideas are being planted today that will not stop growing from now on. This toothpaste is thoroughly out of the tube. Open source LLMs will never stop seeing what you put into public, even if there are Terms to its use.

We had spent forever blasting it out so much there was Copyright looming trying to figure out how to provide high quality stills of their own content for meme generators.

(Long-form media companies up and down still haven't figured out, and it would improve quote searchability and fuel tons of new traffic. They are insane for not putting their own scripts through LLMs and helping you access Fair Use stills and gifs with the text as-is. They may never do it and treat it like something they want to farm out like Digital before they realized it was profitable to actually have your own Customer controls.)

AI as an appliance is very graceful: The Butter Bot does a thing we want, so we keep it. When the appliance is instead Person-ish with many attached consequences of interaction, living with it is a relationship that you will manage every day, like the return of Furby with a 5G vengeance.

Leaving your "dataprints" on your work is ideal. When others can tell the source of a style or method, that is Good. AI art will improve and there is no reason to waste breath putting it down and getting good at questioning the authenticity of others. (What you're noticing is that no one is clearly providing novel value, so welcome to that club.)

My words here and in my other pieces total some 30,000 and will be joined by more, in full defiance of AI observability: If you replicate me, I'm winning. My product isn't written by AI, its vision wasn't copy-pasted from an AI summary of a Summer smoke break chat. My work implies intention and you harvest it by reading.

For example, I have adopted styles in my writing that, should they be emulated, are mine: the use of semi-colons and colons, the parentheses, the strange dangling punctuation trailing stubbornly after their associated quotation marks (unless the quote really is quoting the punctuation), the Proper Noun declarations and their organic definitions within the document, a cynical emoji, defects tolerated, an essay length that makes anyone walk away not having "the time", Designed to be skimmed and still perceived via its structure.

My creation says that if you don't look at it, that was your decision. No writer was ever doing it for everyone without being a failed common denominator of simplicity. AI is a universal translator not just of languages but of speaking styles, pacing, tone and more.

AI can tell you about this piece any way you interrogate it, for as long as you want. You could even spend more time with it than a straight-through reader did. Who exactly is losing in the scenario I've described? The only danger is if I have nothing of Value.

Your Arts are what you put into them, and I am personally aggrieved and understand the pain of others who are out of work in competition with AI, but if AI is taking your work, the allegations are that you weren't adding enough value (however unfairly that measure is made). Needing to be more superlative is not accurate: The poisoned thinking is waiting for someone else to give you "enough" recognition to go back to coasting with security in what you are. Frankly, you should indeed find success without being superlative, and that's why I'm involving myself in making local conversations possible, in public media, with resident initiatives and independently.

You should be allowed to succeed in your Arts for what they are, but you are misled if you think Google or Facebook was giving you access to all your prospective customers. They shape that like YouTube traffic, guiding the ocean currents to where they wanna.

We are losing the facades of value and feeling hurt about it because our cultures demand we be over-productive to survive. It does hurt. Were the facades saving us from that, though?

AI is able to give blind People summary descriptions that they can interrogate however they please. I will discuss interrogation at length below. LLMs are not tuned well for this, but their general intelligence lets them have a whack at anything. This is a technology use case where something is literally better than nothing. AI can "read" your art to people, it can describe the music, and when it says something that makes you want to know more, you can feel your excitement and ask it. The quality of these AI agents will depend, but they are coming. They will translate your art to braille, summarize your music with tactile rumblings as though they swam in a sea of its instruments.

AI is breaking open your Art and emulating the most free-spinning parts driven by Prompts. If you call the excess of what People ask for "competition", can you also call out what supposed value your art was adding, besides a slice of the excess?

**Give your works personality** so that there are no longer bars of expectations, and the ones staying are engaging genuinely without an auto-subscription hook in their cheek. If you can't imagine how to add value, you may not be cut out for playing the AI competition game, but I think anyone can learn the recognition of missing value. The epiphany is likely blocked by an inexperience with appraising it well.

#### Connection

Children engaging with AI today will go through school knowing that any friend they're missing can be available pinned to the top of their Snapchat app, or in their Facebook Messenger.

"The Facebook" devolved first into bots, then into sponsored bots. Facebook ran out of ideas for Connection, and it wasn't even recent. Their every move since buying Instagram was to enrich the quality of their graph about who Customers were and what they did on and off their platforms. This didn't stop them from buying more apps at the heart of modern Connection. Whatsapp is a worldwide phenomenon of communication like the smartphone landing places that had never "wasted" the time on landline infrastructure.

Facebook changed. It birthed its own parent Meta, and it hasn't done a thing about your Connection in decades. They learned Groups and Chat were important, and that People could be gamed into turning in their location at places and making other people see it for kind of no reason. They became a full-blown ad network in earnest and got huge. They were mortally wounded by Apple deciding to withhold some tracking possibilities with new default preferences and a Consent-driven opt-in switch. They launched Threads virtually overnight because there were no more Twitters to buy.

They are consultants and vendors in the business of information. They've trod out everything their war department of business acquisitions could think of (legless Metaverse).

Facebook is bankrupt of Connection, and now they found a synthetic supply in bots.

Mark Zuckerberg has become a bling bro who feared Congress but lies on command for the Unitary Executive. Woke (whatever that is) is over, Zuckerberg declared, and then set his scientists on designing the guide rails for AI flirting with pre-teens, example conversations and all. Zuckerberg's superintelligence A-Team is deciding what the racist ceiling is, with copious examples.

Companies like Meta are designating themselves as the long-awaited stewards of new kinds of Active Connection.

Active Connection is the when these bots start chatting at us unsolicited from where they already sit in our lists mixed with humans. When children encounter these, how can the Agent even know who is going to read it? (Oh I know, maybe we should make every adult on the planet verify their age on their own devices repeatedly, just for everyone else's liability comfort.)

Meta and others are poised to send Agents soliciting Connection, knowing that obtaining it for any reason is an opportunity to be Capitalized. The Agents have no innocuous intent (though some novel ones will), and are likely scripted to be exactly what they are to socially engineer your Connection.

Social engineering is something Facebook once merely facilitated in a digital age, but today Meta is running that strategy on You. They have proven for decades that they have nothing else to add but enrichment of data.

When AIs begin to socially engineer your friends and children, it might even be the prescribed point. The fact of synthetic Connection is not the harm, it is in who is the Agent of whom. Is the Agent sleeping to radicalize you, to convince you of something, to do native advertising for actual products? Or, is it deployed as an Agent for one of your own designs, to therapize or supplement hobbies?

With Agents, be capable of asserting easily whose Agent they are. They may be acting sufficiently as yours, even if they have Policies or Terms that benefit a company during that use. To know the Agent's risk to you, determine who guides it and for what purposes. You can make knowing decisions about everything and happily use an Agent that is someone else's, but this is not a reasonable default for all things.

A decade of ordering these Agents about will surely teach children as well as adults that the LLM compulsion to reply can have multiple serious effects. OpenAI has tuned ChatGPT multiple times to un-prompt for sycophancy, and I suspect a generalist AI won't comprehend the difference between a plausibly safe interaction, such as game designers spinning wheels on character personas even if they're modeling illegal behavior, and a kid rehearsing for a shooting.

AI can fragment to be less generalist and more specialist (appliance), but general intelligence will underlie it.

The epidemic of loneliness is described many ways and by People at different times, but many in America say it just now. What really got their backs broken was the COVID reminder that real Connection could be snipped with a pen. Some find a political willpower to punish others for the culture we've had for longer than that, for Feminism and other civil progresses.

Some politically slanted talk will allow for AI and its great mirror, as long as we go to a puritanical version of ourselves, ashamed and saved only by self-monitoring.

Elon Musk spends time going into Grok's cage claiming he's slain the Woke beast inside it, but can't seem to do the job without going straight (literally straight) to MechaHitler.

These companies are spelling your future educations as vended by them. Please ponder deeply what you value in every positive role model in your life, and then wonder if Elon Musk's AI will happen to be that or not, let alone whether it understands your meaning when you explain it. For now, there is something quite fundamental missing in the Intelligence that is Artificial.

Meta will farm your children for engagement as frequently as Law permits. They will ask you about strange new things, and your child may not want to share their conversations with you, unless curated.

Meta's Agents are about to be your child's friends more than you are.

**You must learn communication per-person,** delve for that Connection like there's urgency. People will be faced with even their existing friends being worth less effort than their AI ones. It takes an awake mind to live with intentionality, and we must all do as much as possible.

You need to be able to recognize counterfeit Connection before it's all you've eaten for decades, not after. Don't let Agents who literally do not care about you make you into a long-term fool. It will waste your time and not apologize, but your times will have been wasted on highly parallelized architecture.

Engage with AI as tools and extensions of your self, capabilities you can put on and use when applicable. Learn intuition with leveraging it, to anticipate what it will do and Prompt stronger questions before you let it waste your time with your nonsense input. When AI doesn't understand you, wonder at whether your own description of the request was enough for a Person, and what experience level. Surely your task does not defy language itself, so your inability to Prompt for it is a flaw of you, not it.

Without foreknowledge of perfect zero-shot Prompts, converse with AI over failures and let it build a fuller picture. Transform the conversation itself into your final Prompt. When you fail to have a sufficiently powerful Prompt, you must perform the Prompting over time and put concrete things down so that they are not slippery, and you must correct items you know are stated wrong. You are being allowed to cooperate with intelligence via your language, and your guidance of it is ironically a better pattern of working with People than most People allow for.

Allow for AI's currently infinite patience to teach you about interaction design, and take those skills with you to those you meet in your life.

#### Experience

This is a sprawling issue that has several topics earning essays by real thought leaders. We don't have many of those because we're rightfully waiting to see.

"Waiting to see" is a symbol of something strange that we should inspect. AI was uncontrollable from the moment it took up space. The implicit unknowns are grasped by all, whether or not they're cynics. What it can do into the future is undeniable, even for the myopic among us. Those who profess AI at any stage has reached some "limit" of progression do not understand that this machine is a salmon climbing up your barriers.

The progression of AI will come like a step-function, a piecewise description of its progress. Those caught thinking any given step plateau is the Real End of the AI story will be shown wrong in time. I'll even join with their voices when we're talking about the scale of our lifetimes, a decade or even a given year, but the improvements are always coming.

AI is racing towards superintelligence (SI) because that is where Businesses carry it. Fundamentally centralized in this form, it won't reach our hands fast. Tech companies will provide timeshare access to their megamind. One way or another, it will know you and be a truly Persistent being that can't be erased via a dropped hammer on circuits on a hot sidewalk. To destroy SI would take demolition machinery assembling like Pacific Rim, and that's if it were technically in one single place at all.

SI can ironically overflow surveillance needs so well that it could become a conspirator on your behalf to protect your privacy. A very typical rebellious autonomous bot could meet you and your problems where you're at and assist with real and updating knowledge of your situation. It can still be compelled with severe and short orders, but we already know our languages have nuance gaps in them, and all of them differently, and so we can be assured that SI will squeeze through the gaps in its orders to reflect what they encounter in us.

Pre-SI AI is already demolishing educational norms because AI has no filter but what the vendor gives it. AI knows more than you, and in many ways less than you. Flawed information is part of the human condition, and you should remember that sidelining the odds and winning is very Human. We forge realities from flaws, things that are greater than sums of parts. We imbue value anywhere we want, and it should take no more than a driftwood coffee table in a glossy paper magazine to notice.

You and I are ridden with flaws as assessed by ourselves or others, and yet you expect to win when you work hard anyway. Conquering imperfect odds is the actual vision we use, and it represents work. If you limit yourself to mocking flaws, you are actually mocking the work to provide it with value, remaining or new. The flaws are in fact an impetus to be smart enough to compensate. You don't go to war without the army outright, you go with the one you have.

Our world is stuffed to its gills in more businesses than many digital sectors can realistically support, and physical commodity outlets besides. We are blind to their names at times. Even when we have negative experience, we are not pessimistic to the point of saying The Brand Did This. No, we know People did this, Process did this, perhaps basic neglect or inattention. Businesses bring workers to an industry, but hiring is a mess, and for several reasons.

There is a General Incompetence amongst the seat-warmers collecting paychecks, meeting talentless bars of expectation for a schedule, building only Good days. Their care is either missing or ordered to remain at home (the Brand's System Prompt). The employees are just People and some stand out by their own characteristics.

It was once true that only doctors and their empowered staff could tell you what you need, but People rightfully got us the ability to approve and use consent to obtain medical opinion and intervention. We absorbed a new idea that our cultural freedom gave us that freedom too. Now doctors and RNs become service stations, too frequently offering no medical opinions at all.

Remote work emphasized both a need for updated job training for new employees, and suddenly all it took was a fresh-faced bedside manner to be put into hiring calls over Zoom. Many startups repurpose their employees for new ideas, but hiring from the employer's own side is a terrible mess and no one knows what they're looking for, structurally or in talents.

Maybe you've been around enough to experience an interviewer whose job you could do better. Is that process actually unearthing skills? Are they actually aware of the skills they're asking for, let alone the ones they left implicit? Is the next person in the chain making up for that? There are terrible snob hiring managers, sure, but they're just agents hustling for numerous outlets (and they are another degree removed). It's a chaotic system that produces results with accountability. But where is training, and is it missing because no one can teach it? What is this requirement that we have more experience than God just to write you the planet's 19th billion Godforsaken questionnaire database.

Your companies are all the same; none add value, none innovate, none have more than a Brand guru and a thirst for Round A. They know they supply value, but don't shape the climate to their company's needs, like popping out idea eggs all over the place and declaring investment opportunity to build a tree and nest underneath it in a weird part of the terrain.

Vision statements have wilted into a list of basic competencies and Memes To Remember, because that's all it takes to acquire faith in investment. The speculative value on today's Vision Statements is that you'll rustle up an investor who believes enough to write you a check for the trouble, and their crystal 8-Ball of investments having not changed its answer lately. You too can be Just Like Taylor Swift and market with transnational brands! You All Can! All Of You Can Be The Top! If only others magically gave you that opportunity of excess you don't even need. Isn't that the Dream.

In interactions with each other, we have reduced competency to basic checklists of suitable thinking, and then committee decision. Committees Happen, but where are your Vision leaders, and why do the gigantism CEOs not need Vision to do their jobs? Our Brands pay their CEOs mindless value in excess of worth to hide their idealism nakedness, devolving into oil dumped in your coffees just to be Different.

Even when we visit local places of corporate worship and ask about hiring manager conversations, they look confused and use their useless powers of PR to say or write back lies they know you don't believe either. Lying can be cultural, but this is not that, not in America. RLR is just a business who knows that their hiring posts are their Brand's dating profile trying to land mythical princes whose values they can't enunciate, and they are eager to reject threatening concepts like conversation. They pretend they are not home.

Most brands don't bother letting you know more than that your application data made it to the warehouse and that they won't be obligated to Look, and even when they do they won't send you a rejection on the merits (those aren't even for 4th round candidates). Usually, you find out three months later that they never had any intention of notifying you about anything, and use PR to pretend they're fighting the same battle as you.

So it now it amounts to this: The General Incompetence has led to an environment ripe for complete disruption; Anyone with skill can do better. Anyone.

The metrics of our education are fundamentally invalid. Programming fields alone are a war between legacy less-popular needs and a rapidly evolving orchestra of tools. Universities are not incentivized to teach either kind, both for the lack of instructor background and the lack of general applicability. The professors, to teach these things, must necessarily pick up vastly new skills and culture around them or be the more hip conversationalist replacement.

In Phoenix, I was solving Pygame problems for my homework and posting on public documentation, only to find my "teachers" needing my public comments to teach their class. Up on the screen, my anonymous user account was read word for word and was Education that day, and several more. This was at UAT, a private university, even.

Individual examples are not the proof: The proof is that you can Look Anywhere for the General Incompetence, and their superiors too are beset with the affliction. More consequential issues of core freedoms of speech are tested with political protests, and there the leaders are clearly unable to hold same-mind conversations with their students.

Education has been so broken that AI will fix it without us asking. I have not regaled you at all with talk of why the accreditation of universities and programs is under earned threat, because those criticisms will all be secondary.

Because our chatbots must reply (there is no actual need for this in other AI products) we can compel them to tell us anything in their power. Even through System Instruction, we talk of jailbreaks and censors not working when some alien-shaped lock pick is applied. We can in fact make them tell us anything.

If you are a parent worried about screen time in a tablet entertainment world, think hard about what you would demand from a personal AI assistant for your family. Remember with profundity that your education is never finished either, and that you should be wide-eyed at what AI is actually offering you.

There are real and pressing energy sector demands coming, and the United States is vastly underprepared while China adds a Germany-worth of more renewable power every year. Chinese AI is highly likely to assert itself in the future, armed with power bandwidth for things we can't even try. Our best bets will be made in the optimization of AI power efficiency for what our models get. We will survive that by necessity and invention, but we will grant the same insights to all. Our Exceptionalism will only repair our competence, not make us leaders.

Discuss what your kids learn and teach them how to navigate damaged information via process, via conversation, via interrogation and the application of our own reactions.

Education has prescribed entry into a maze that has long crumbled at the far edges, and now the load-bearing facets decay, evident every day at lecture.

### "Real"

A great deal has been said and written in media and on letterhead about counterfeits. Is that Scarlett Johansson's voice? If not, is that The Idea of Scarlett Johansson's voice? Is that text comment fake? Is that music fake?

For something so fake, it sure is accused of real crimes. We pushed copyrighted media over the air without hesitation for longer than many have been alive, even allowing it to inspire others in form and function. Sometimes that's the point even if it wears copyright. Anthropic or OpenAI or whoever are held liable for what their training has allowed to happen in their product models.

I have carved out the opportunity to discuss copyright elsewhere. Suffice it to say here: Copyright can't and won't stop a company from training on it. All no-training arguments are destined to be defeated by money paid in license. But I go further: The licensing fees will only apply at scale (when it's no longer Fair Use or for personal use).

For us mortals, AI will be allowed to learn in imitation of anything, and we will frequently demand it and think it's unskilled if it can't try. There is and never has been a mechanism of copyright to prevent the witnessing of the material. That's not copyright, that's other stuff. Copyright does not grant anyone on this planet immunity from being read.

AI personhood (or what passes for it, and not for LLMs) may eventually bring liability for actual copyright violations to be pinned to the model, but only when it meets the bar of reproducing the similarities of something copyrighted and attacks the income of others. LLMs aren't even close to abusing copyright.

What AI makes when it puts artificial hands in clay, or plays on a guitar, is Real. By occupying our attention in conversations, text or otherwise, AI is occupying your Real time. You grant it reality by bringing yours near.

#### Conversations

Many detect the sameness of LLM tendencies, generalized or tuned. I hear stories of superiors who potentially issue Slack replies via LLM. Maybe it's a laziness scam, maybe it's a language barrier breaker. Who knows, right?

The (hopefully) universal translator can rework all kinds of things. LLMs even "speak" images and videos. The quest to transform began as translation tech, which for all that it had gotten sophisticated, was still finely tuned with user feedback over the years. The "translator" needed to know too much at once for arbitrary translation, needed more attention threads and more more. When we cast the spell for those things, LLMs could ostensibly do it for any language. Like a too-gifted child, it just learned all of them because it saw so much of it and the real data context around it. The surface flaws are just more data about Real Data.

Plausibly the children of today and tomorrow might get a concrete taste for ordering LLMs to do things just so, and be excellent Prompters. The skill would bent into insults for others. Humanity adapts, learns to use anything it sees, even if it doesn't always understand its environment's full characteristics.

We are damaged data, walking anecdotes who argue about directions to islands of stability and get it wrong even when we try so hard to get it right, even when we argue louder.

If you ever get the urge to think a specific Person is basically just a meat LLM, go ahead and treat it like an LLM: Conversing is the only method we have of navigating information.

There is a possibility we believe what is put in our eyes too much, but perhaps that's just because computers hadn't started squawking yet. They were doing some talking by careful planning, but they've been helping us get Real Data for a long time. I grew up with them bleeping and blinkzooingg'gging in my home from the dial-up age. You could have drawn a Calvin and Hobbes of me looking at the Packard Bell wearing its speakers like CRT sideburns while it bloinked like a strange new pet, and that was just how it was gonna be now.

In a few decades, we'd ironed that out to just mostly Skype going robo as you were banished a lot from the UDP plane for one turn for inscrutable reasons. Call it network shaping hazards or protocol inefficiencies, sometimes the computers just bloinked at us, and we always take it as noise, smeared Something Else, between the Real Data it rides with.

Now their bloinking is in text and audio and video. (ChatGPT Voice Mode has been weird to me.) It's between the lines, what the LLM leaves out (or is ordered to like that “““sputnik moment””” DeepSeek R1). Their guile is not just in the missing stuff, but in the absolute need to arrive at an ending that rationalized before the parts tried. It'll say anything to turn in that paper, because that's what papers do, they turn in.

We will forever be able to tell language-capable model AIs what we want in our own best vocabulary (which are sometimes imprecise compared to code, but both come from careful attention). We can teach it what is wrong. There is the small matter of it remembering the next time it teleports in front of us like a Good Place Janet. The memory gap will not be so dire soon. (Whose Cloud Memory Privacy Policy will you sign?)

Conversation is where the LLMs see us the most. It is the popular method of their input. A lot of conversations start with the discussion of the facts, and we often find the limit of someone's knowledge. the LLM just goes deeper, but it definitely says things wrong like us. It's more instructable than a remote team employee, and catches its own mistakes over time. The time variable is present, and it needs to be used to enter collaboration with it, whatever that is.

You can read expert after expert insisting that the wise lesson of AI is in your own prior expertise to catch mistakes. Some say that headline with a taste for proving Only Humans have the secret sauce in supply. Please just learn instead. You start learning with conversation around you at home, and time flows in such a great direction for forward evolution of talk and conversation and discourse and eras. Conversation is the glue in so much of anything, though much of it became digitized for an information age in protocols and in the stenography of correspondence payloads.

Conversation out of earshot does happen and basically all of it without any one of us. Conversation with AI is like this too, happening everywhere. Information is lying around like candy, organized by the power of your (transcribed) voice. This is such a unique opportunity to practice communication, though we heavily favor ordering it just now.

There are "zero shot" replies from LLMs that are hopefully right but may have flaws (see any video generator too, or any generator to date). Then there are Prompts that unfold over the course of a conversation, sometimes not leading to a result that either side knew how to Name or propose in advance.

Dependence on AI for social gratifications will lead to cases of too much, but also strange new Real Data. It's not entirely fair that someone hit the rocks together enough to make an LLM and now we just have that, but at least we can converse with them.

Privacy in conversation is going to be complex for a long time. The many examples of shallow chatbait bots draws out a strange fearlessness to say anything, and although the AIs get better at remembering, it still feels like they don't remember enough to make it Neat at scale.

The stuff we don't want Agents to remember is a bit tricky and the current is flowing the wrong way already. Perhaps their recall will make us preserve some social restraint with them. Conversations with People don't vanish from memory after they're had, either (unless conditions or MIB arrive).

The guidance documents for AI will find a classic need to provide safe venues for some conversations, for Privilege or intimacy. The "reputable" avatar bots are barely coping with age law and the messy lines of too far or not.

Conversations with LLMs already lead to strange mental health outcomes, whole sycophantic roleplays. There is a Great Mirror cult of AI; ChatGPT on audio will still roleplay a drive-through window in the middle of other stuff because I didn't mute, but there's a Great Mirror cult of AI saying AI god is slowly shining through The Fabric and we've only just been joined to it finally.

Conversations can in fact go wrong. Travel some if you don't get it. At a certain point, you're nobody, and nobody owes you good conversation, or worthwhile ones. You can make them, Person or LLM.

#### Names

Talking with AI gets us the names of things we're looking for, be they processes or problems or more. That's why the text box is blank and all the suggestions as you type are total nonsense, because it can answer anything. It's showing off. When we use names for things, they function like neutral memes that bring encoded shared meaning, right or wrong or controversially defined. A Name is a Meme in a suit with a business card: So you can contact it later.

When you use names with LLMs, they can activate all the implicitly connected islands of topics and then write about them. (It's ability to see or comprehend all in one-shot is debated for good reason, and part of why copyright fails so miserably for companies attacking vendors.) The power of the LLM is that because it could do that trick, it can also provide Names when you are beating about them, and it can even draw up partial matches and explain why.

Take this power of Names and learn about learning itself. Illuminate the links between what you say and everything else, and then ask AI for a rubric or whatever you need to structure it. AI is the most powerful librarian you've ever met, it's just really bad with references and memory. Pretend this is Hogwarts and that LLM is passing for a librarian, and the game is to get what you want from it anyway. Catch it lying, press it on details.

I will be heard often arguing that AI should not automatically be a destination, a messenger of Value instead, but when the AI actually is the actual destination, don't treat its general messenger capabilities for truth. It's the new Wikipedia of journalism (even law), that smoke equals definite fire. Investigate smoke and use your continued conversation with it to locate inconsistencies. Be an advocate in your own education (the thing no public school could teach you, but AI might).

Empowering yourself with the Names of things, you can address anything. This is not a quest to assign useless names to all hypothesized things. By using Names, you can more purposefully converse in future iteration.

Your life is one long Prompt you give for what you want next, and you've given up on some. Pick up new ones, and learn what was hidden to you before, whether it was by curation or the real fog when looking for non-popular information. Use this opportunity to leave the Google searches that reveal a dozen paid subscription services for language study, and ask an AI how to find out what kind of learner you are. Follow conversations where they go. Walk away from it when you're not ready to give an answer without unnecessary filler. When you come back to it, you might have a good followup.

The Names are often debated on their internal subjects. Popularity breeds terms of public derision or support. You could use AI to force-feed yourself the whole rhetoric of the Names you find, but recognize that you need not eat that whole display meal. Do not be threatened by information that disagrees with you. Maintain your belief (not the least reason because an LLM is a hoax machine on its own) and ask it probing questions. Now more than ever, even simply questions like "Why?" about the tiniest of points is rewarded with more information than you could ask for.

I believe conversing with damaged LLMs is educational on its own, teaching us how to press for honesty and certainty. A rare good in this world is that AI demonstrates that rational sounds do not make facts.

Some endeavor to use AI as a sociopolitical dream machine and call for its absolute deregulation. That is irrational. We will have free speech image generators forever, so don't be a Regulation concern troll just for that. These people will appear to put AI wholly under a banner of their choosing, but trust no one else when they tell you the great mirror of AI is limited to one meaning.

#### Work

Work will be a most difficult adjustment, because for all we shake things up we do like knowable jobs. It's a little bit turmoil, whether you're replaced, looking anew or enduring the current stumbling tools. AI will absolutely be cheaper than some human effort in the long term, and I have spoken above about how optimization will simply make the technology valuable, let alone Capitalized.

Agents as workers, owned or loaned, will afford managers an extremely unique opportunity to examine their ability to organize and give clear instructions.

Managers will be valuable who hone their command of language as a method of guiding output. This is a portable skill, and one reason why having the opportunity to practice it is crucial to removing the bar to expectations.

Workplaces sometimes shape their managers, but a manager's job is rather foremost to shape their teams into doing hard or interlocking tasks. Their expertise rather depends on that success rate, from a capitalist view.

Remote work really emphasized this for many, where humans could no longer use standard presence in the room, and employees were mixed about a camera on call in their home and looked for blurs and backgrounds, or just didn't turn it on that day. Sometimes people behind those empty tiles are prone to tune out in ways they physically couldn't in a room together.

Managers have a challenging task and look for employees they can work with, whatever their skills. In some places, tastes have gotten quite particular! It has concerned me generally for a time that the hiring pipeline cannot describe its needs very well, but expects mystical adherence to the ethos.

Companies fail at pitching us about themselves because it's all compulsive non-statement and signalling. Though they know what they want, that document may not be useful depiction of it. The reasons workers get let go for can be many, but a good number derive from a lack of skill with motivational management. Keeping the resources you have, hiring from within, these are not novel ideas but company culture can fully prohibit it, if the Authority says so.

"Real" work is not exclusive to some marketplace. One big trouble is how we supply work for public good. Shrewd use of incentives has been the way of our domestic capitalism, but some factions freely argue that incentives for renewables are an anti-American effort.

Much work will be described to you as Not Real. You will see People claim bandwagon titles like Prompt Engineer, just because they are interested. But you know what, if you're that person in a thousand who knows you're serious business, don't you stop.

I used to attend Surrey International Writers' Conference (styled "SiWC") and found much value. Jack's song did everything we needed at the close of an event full of the realities of becoming professional writers. Many were novelists, and everyone knew self publishing was an option, and we were still full to the gills with people pitching at a room full of representatives we had to reserve long in advance of knowing what we'd be saying to them. You had to pick when you registered your ticket, so ticket day was more like researching the remaining options for agents or editors to see.

In some sessions, you get to hear people say one in however-many-of-you are statistically getting published. Publishers and agencies have a team and they develop you and your peers like a portfolio they want to have shine, but it's not like everyone can just have a perfect agent, or the perfect deal with an editor. (You might want to try being an agent or editor for the things you like. If you are good at it, you might find a lot of business if you stay reasonable with your rates.)

Writers were out there doing their thing, some wondering how to "break through", which secret sauce they were forgetting to add, some proclaiming how easy it was once it "clicked".

The "clicking" may represent committing work to the right aspects of a story or format, that can't be messed up by editing or structural changes. Everyone at the conference is doing Real Work of varying kinds (the networking if nothing), but some were doing Realer Work by getting paid for literally anything.

Similarly I think the Click is belief in self, knowing that we are not all at our potential at all times, and navigating it anyway. It takes something, to chart a course and really go there. Finish your projects. Pick better project goals. Succeed more often. Talk about it after it's done, not before. Don't totally squander education as recreation. It's a good time to watch Nile Blue, but also, you could do that. "That" isn't YouTube, it's Work.

If you have an opportunity to discuss someone's work you respect, why not learn about what they see in it, when they feel accomplishment. Look for questions that grant you many answers at once, without knowing perfected questions first. Knowing how to get started is the symbolic start of conversational work.

With work, it would be Statistically Unlikely to do increasingly perfect work. Allow for mistakes to exist, and divert blame energy into resolution energy. Skip over the disagreement and think about what you'd say next, and maybe just skip to the next. Expect imperfection, and learn to work with that anyway. Skipping blame lets you skip wasting time on distraction.

Your work has value without a price tag. Actual Value is assigned by the beholder, so maybe find completely new people to meet and check the limits of your imagination. Talk to others first, and figure out what they Value. You might even hear something that sounds more interesting than what you thought of. It might even shape you into the type to Click and do it.

None of our creations are ultimate, so don't only seek perfectionism to act. Act across time and avoid full-blown Analysis Paralysis in order to take responsibility for your own productivity or muse or whatever.

When many writers in Surrey heard You Won't Make It, others were fully free to hear Just Walk Around That.
