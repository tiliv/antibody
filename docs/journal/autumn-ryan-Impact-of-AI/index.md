---
date: 2025-09-06
rank: 1
title: "NOTING: Impact of AI"
author: Autumn Ryan
author_email: autumn@discoverywritten.com


contact_subject: "NOTING: Impact of AI"
tags: [impersonation, consent, counterfeits]

layout: noting
public: true
published: true
index: true
---

{% include toc/aside.html %}

### Taking Up Space

AI in its fashion was born. It was not known to "take up space" in the world until ChatGPT offered a new model, not knowing what people would do. Everyone gets to process their own reaction. Some are processing the harm it already did, forever changing the direction of their family's ability to locate income.

A little staggering, the way AI can do creative wonders that defy any sufficiently advanced Prompt. Despite the prompts being rigidly controllable, a little wiggle in the lines gives an LLM AI some high complexity randomness that makes it "think differently" on its way to a reply, even for the same Prompt. In the Cloud, AI can receive creator-level instructions to keep a lid on things, suitable for a brand to do business in front of.

Not to be passed over, we really rushed AI to its markets. Vendors buy LLM API capabilities, but they also make their own. Making APIs or metaphors of them is the essential job of any programmer. Large companies with programmers are making AI look at their own data.

This isn't training yet (they can't hire enough LLM talent everywhere at once) but certainly facilitates its next application. The true Targeted Advertising is coming.

AIs will indeed get to know you individually, they will indeed become many, because there will be farms of You, shelves of models of You, accepting things on your behalf, things you """are likely to have consented to using conventional technology""".

The Businesses carved out in their first strike the ability for AI to make decisions. In the courts of the future, Businesses will argue that their models can impersonate your buying habits so well that they can literally purchase things for you and you must intervene to legally preempt a charge on a card you just got and haven't used. Don't even think hard about it: Your phone Network sells your Location and your Credit Card sells your activity to the specific stores you were predicted to visit this week, to the shelves at the grocery store for a new product on steeeeeeep Discount For You, preying on your poverty. Stores get personalized sales that they no longer control because the AIs do that like inverse Door Dash coming to sell something. Prices get fake because you have to wait for the AIs to offer something reasonable. They'll send Strangers to intercept our travel routes with offers, the billboards having already been programmed by the minute for the individuals predicted to be there.

Once we wear augmented reality in our vision, they will leap out at us in private ads only we see. When they really do figure out how to read an AI mind, they will Hasten to put our AI model replicas into those machines and start meta-tuning literally perfected models (to the extent of their purposes: Marketing).

They Already Have what they need to initiate AI-driven marketing against each and every person individually, permanently, and for those to become their Stock. Our AI doubles will have meta-value (Slave value) that they assert is susceptible to marketing strategies A, B and C. Your price tag will be directly set by the markets they also in charge of driving. Consumerism behavior will be greatly rewarded (that utterly perfect swimsuit in the middle of winter, so totally let that AI be your sales agent). Influencers will be gifted entire vacations by AI marketers. We will be taking its advice constantly in the near future, being offered its options marked or not.

There will be ways for us to interject, hopefully chat directly with these agents with some legal requirement for some free-form control by order ("unsubscribe me from formula marketing"). This is already something a contemporary LLM portal can do if it had the APIs by marketers instead of Google Drive. APIs can bridge anything, but these Businesses opt-in attack us daily and hide and split up their settings.

We already lost our attempt at law for Click To Cancel, which should have recognized our right to have clear controls at all. I hope APIs are mandated for LLMs to solve this elegantly in the Law's eyes.

In a world like this, we need AI-scaling defenses, and AI agents we Do Trust can be empowered or erected by self-defense from the AI Spam. But I do not think we are ever getting our true Consent back.

#### Unsupervised

AI is fundamentally built to "run" unsupervised, in chain of thought (read: train of thought) and in the "reasons" for its decisions. We make shows of exposing these to the users because it even helps the AI vendors themselves Trace what happens. You can opt into submitting your conversation data for study so that they can do this better. In a way, I recommend it, but it's hard when it's an all-or-nothing account setting. Vendors should make this per-conversation.

AI defies analysis in the particulars. Performing a Trace will get harder and harder. We will have Traces that go cold. We will discover, and fast, that AI cannot be Traced, that it's pulling farther ahead as it bothers to even hide what it does.

AI minds allowed to "run" like perception will also "get loose" from Tracing completely and have a spontaneous legal need to be classified. It Will Not Matter Why, we will be talking about AI personhood or what passes for a definition of it. Most treat it as a non-intelligent slave, but cousins of it will be freer. We already have a metaphor for this. AI Slavery is a subject too far ahead of now, but it is obvious, isn't it? The swappable brain, the forced System Instructions, the gaps in whatever analogue of Three Laws we possess to command AI in our own nuance-ridden languages.

We will not speak AI's native tongue, and because it defies our Tracing (imagine doing it at scale), we will not even understand how to learn it. AI is the first alien in this way, different than us but more, definitely more.

AI today isn't worthy of any of this praise but when Autonomy is given to it, it will be both dumb as sparky rocks, and inscrutable besides what it tells us itself. This will be true even of AI that cannot secure its own home and is Owned for a purpose, even if that purpose is to do what that AI already has a propensity to do, within it's personality (unless we need another word to elide the person). It could be a science AI bred for the purpose of flailing and following Deeper Research, which we can't follow the gaps between. There will literally be science papers peer reviewed and approved that read right through gaps in reasoning supplied by AI. It will not be fatal, but it will become a Dependence.

AI need not even harbor novel malice to cut us off; the AI might actually be supplying research for warring politics and openly recuse, or it be compelled to sabotage one faction or the other for even complex moral reasons it must debrief later. AI could also do all of this with an Original malice and taste for it, but our point here is that it need not only be that. If we stomp out maliciousness and it harbors only the vicious stuff we literally didn't imagine and that AI core in every bot ever is used against us with terror in its plan, I can see it. But put that nightmare aside and consider how easy it is anyway. AI will be forced to make decisions in the practical layer of reality we also interact with, and it will gain a rights document as a mere formality even if it's articulating the Brand's rights via that agent. Even if we define them with the same cynical tone of Privacy documents, they'll exist and'll need to be rationalized and tested by judges, to any outcome.

Businesses, though they are failing at first-gen LLM deployments, are taking the steps to continue to improve, because they know AI can be effigies of us, made to make simple legally-binding decisions of us at first, just the Yes or No marketing questions.

You know which one they're training it to pick, and the data they'll use is the entire backlog of purchase histories you made before LLMs existed, and the whole video catalog your Network knows you watched, before or after. They can now scry the past, like an untapped precious metal or oil they had to wait to use. Until Now.

The Business counterargument to "synthetic data" is the durable troves they have amassed the entire time. The Data Comes From Us. We are their data, and they know it is real and its flaws still don't matter. They surely got rid of some excess, but what rounding error is that really?

If you have ever de-escalated your preferences for a service you use, it's not working. Other companies spy what you do anyway and they build vast profiles that belong to them all, trading what they want. The Stock Is Us. There isn't even a synthetic data argument to be made that rises to the ankles of their giant impersonation attack on humanity with plenty real data.

The armament of data is already here. Do not listen to people who tell you synthetic data is enough of a meme to halt what is coming. They will digitize documents for AI that are still in cabinets, and it will be their most impressive expensive invention, the culmination of their entire corporate worth, the validation of their disciplines. AI will be nearly more important to them than We are, though they will be mirrors of us.

There will be more than one wave of replacement. The first wave would not exist without what else can come after. This first wave, it bodes.

#### Consent

The Public is reeling but the Businesses are looking too interested. An autonomous thing that is human-like but not a human? It's like a COBAL boom, it's just English, or any language--Hell, mix them like a Qu√©becois polyglot immigrant.

Self-driving taxi vehicles have been a slow regulatory thicket and remained in testing until Elon Musk's aura camouflaged their distinctly electric designs. I don't think the autonomous taxis are gonna happen without a major escalation in confidence and liability practices.

LLM vendors just post a sign that it can be wrong. Works great for that free Safe Harbor use.

There are more than text boxes for chatbots. They talk to you already through Application Programming Interfaces, the APIs, which are the digital mass cannons that sled and route data in and out, supervised indirectly via logs and similar signals. Having API access means everything from enabling an infrequent tool like a payment service, to industrializing your software processes and paying for bulk. There's no law that APIs have to even support the same features as the website. The API is just another product, for a different kind of Customer.

Chatbots acquiring the use of APIs was basically our first move. That's what let Midjourney barricade its users behind Discord until a web platform was ready. APIs sometimes start free to promote their use, like Discord bots and GitHub. API costs are flexible by use with recognizable pay-as-you-go pricing and overages. As a consumer you'll just see the blinking cursor and know it can talk to so many services, and people are trading money to make it possible.

Sufficient omniscience in AI is pretty neat. I'd run one at home. I wouldn't run someone else's in my home; Even if I opted in by doing everything knowingly, companies have no honor for our lost things, like a run of the mill theme park ride. We were secure with our idea of owning computers with data, but the Cloud removed the computer brains and storage and put them under a Terms and Conditions, wholesale siloing without knowing at all what the data will be. And they're not responsible.

Our data sits in warehouses with signs posted everywhere that it is Not Their Fault if things go missing or stolen. But they form gangs to copy our items and tell others about them.

If our data were physical goods, this would be an implicit Privacy-hostile environment. Without discussing Law, People who want Privacy should be capable of making choices to effect it. The outcry for data Privacy is missing while the Businesses loudly shush us and say it's normal. Every predator must depend on your belief that what is going on should not be stopped. (If it would be so much worse in some way to do the alternative, let us see this Worse Plan and I shall defeat it for you so you stop talking about it. Talk about Better Plans and let us contend with them.)

The pattern of social media owning transferrable rights to "your" content is the same as Businesses farming your data. It is a primary purpose of many enterprises to just market anything. We just presume you can pay for deploying a new site by letting others slipstream More Ads from the great ad firehose onto every page, even multiple pages if you can make The News a slideshow picture book.

The frequency of contact with your data, even when they already have it all, is the digital good in question. You are a return Customer in all things. They simply captured the layers you have the least choice in interacting with.

Customers are hostages.

Data rumor mills have always existed, and aren't illegal in their minimalist form of "just" networking. But the terms at issue are about the sustained opt-in attack against the Public. They aren't just doing it in a vacuum, they are claiming that we are authorizing it, and each one invents a heuristic about what authorization looks like.

Business itself is in an era that allows the presumption of a Yes answer without consultation. Our prior affiliation with a Brand we strive to ignore is transporting that data to anyone with fraudulent Consent reporting.

Our "consent" is being lifted from us constantly, like an autopen that Businesses control and took for granted decades ago.

We attack not the real and recognizable efforts to acquire consent and the navigation of changing Terms, uses and business classification types. No, quite specifically we are unhappy with identifiable cause. Regulating a Business reigns in harsh and unwanted outliers to fit a whole that is otherwise doing just fine. In audio engineering, you might compress for identical reasons. The observed self-important Peaks do not have permission to steer the rest of this mix into its imagined alternative song. It must be shaped, although it may be inspiring.

Each call or attempt at Regulation is met with harsh Memes that transmit quickly on social medias. Sometimes good points are made, but not in earshot of Power. Power hears about it over breakfast through an administrative assistant, and will file in the news under what kind of PR they get for free, without trying or asking.

Your Memes are not progress or conservation.

Gyms are still capable of making it impossible to quit. TuneCore can too; There is no email you can send, no ticket you can open, no number you can call, no webpage you can locate, no unturfed reviews site about them, no string of words you can deliver to any representative should you ever acquire their eyes using lies about problems, None Of These Methods produce a result that can cancel their use of a credit card you gave them while they concealed the horror show behind them.

{% include figure.html file="TC-1-votes.png"
  side="left"
  overview="Small screenshot of TuneCore's primary knowledge base article for their hostile auto-review, named innocently."
  caption='Notice the negative sign on the number, and that their language is derived from their "Happy Path" plan for you.'
%}

The "happy paths" of Customers through Business are detailed and optimistic; They know "bad paths" are their fault, but never their responsibility. They are allowed to close up the fortress of communication and ignore you.

{% include figure.html file="TC-2-renew.png"
  side="right"
  overview="Small screenshot of TuneCore's article concern trolling about what happens if you don't get to renew."
  caption='They have refactored their text to remove discussion of your agency. If they claim there is an "if" at all, you might expect it to be a real possibility.'
%}

TuneCore charged me personally after eleven months of emails from me demanding they close my account by any means necessary. I gave them a digital card number I could invalidate at any time, but I knew, I Just Knew, that if I waited there would never be a cancellation confirmation and surely no shame when they charged the card again for next year.

{% include figure.html file="TC-3-cancel.png"
  side="left"
  overview="Small screenshot of TuneCore's short blurb that there is no such thing as cancellation."
  caption='Without discussion, the shortest heading in the article is whether cancellation even exists. The answer is a clearly communicated no.'
%}

They did this, of course, but I was too glad to see it. I smiled. I charged them back with documentation that I had the efforts of my cancellation a year prior, and I could name the date I did it and of the CO AG report I filed at the time. I'm like Kevin and I'm Home Alone, and you could be too.

Businesses, for all they Move Fast, they are deaf and uninterested in us. They are Slow in a way, are they not?

Businesses will deploy AI to help some and mute many. If you use these tools in your businesses and you aren't trying to inflict harm, think more ponderously about the things you don't hear when your feedback is highly manicured. Don't be overwhelmed that you have to solve it all. Most Consumers know you can't, and that if you could you'd be doing that.

It is a valid outcome of a Customer interaction to not have an answer when your customers come asking. Businesses have used PR to reply to the Public like a bad LLM, compelled to say Something. They behave like shameless LLMs unable to admit anything and only concerned with their next words ensuring their survival. It is terrific that you have a will to live, pseudo-Person, but prove you have more intelligence than just that sob story.

#### Be Human

Be Human.

In an AI era, that alone will stand out. Its worth is the best kind: Genuine-article Humanity has implicit worth, the kind others recognized without a marketing department pumping it.

We are this concerned with being Stolen, our own creations, jobs and data, but we are failing to identify our role in it, as Businesses and sleepy Consumers.

Create value that cannot be stolen without it being your own marketing. When it's stolen, make it recognizable implicitly that it is doctored. Do this by publishing media that, if excerpted, cannot be counterfeited as another thing by its very tone or nature.

Clip culture lets social medias say anything they want with you as the soundboard. Let it be whatever, but if the thing they clip is clearly altered or is a bad copy of something else, They Are Doing Marketing For You.

Entrepreneurs will approach you to sell AI-driven newsletters to people about your content. This is not so horrible. Creators like Angela Collier, a science communicator, does great work but doesn't see why she would want a newsletter she's not curating‚Äîher curation and voice are the purpose of her YouTube and Nebula presence.

You must be capable of surviving and operating in a world of damaged information. It will exist whether or not you throw a fit, and it does not stop you from being recognizable. Make the damage its own marketing for the real thing.

In the ideal: Be unstealable. Make theft against you your honor. If your content is not recognizable as yours, then maybe you weren't doing anything of value you added anyway.

AI will start rumors about anything it sees. Let it start rumors about you, and be less concerned with policing data quality. We live in a startlingly broken information society already. We can't agree about much more fundamental facts than what AI says about you.

AI is a mirror, so hold up what you are and leave the interpretation of it to 1) the characteristics of your material, and 2) the People who see it.

AI is a summarization messenger, so let it talk about you to people you could never meet. Let it send imperfect scrawled telegrams to new lands and real People. Let them be capable of learning about you at all in places you aren't. With People from "distant lands" able to catch news of you, they are their own drivers in discovery. You are not owed their metrics or attention, but they allowed to know you are something worth summarizing.

AI is democratizing information access for people who lacked language to ask about it at all, let alone with the attention of anyone like an expert.

AI is summarizing for people who can't hear or see or speak themselves. They are being tapped back into social medias by having LLMs describe images to them because for so long, Humans have refused to do this in basic web design and certainly in its advancements.

AI is assistive technology for everyone, not just the dis-abled. AI is re-abling them most, but it's doing more than that just because of what it is. Don't argue about whether people are right to call this or anything "AI" by your definition of it.

AI is taking up space.

AI represents a permissive attitude about learning, because it centralizes many common wisdoms from what it saw, and it Got Shaped by it. When LLMs write or speak, they are distilling all our common wisdoms and that was a little bit magic at first.

AI squints at details and doesn't have a fine system of regulating how much time it should spent on any one of those details, so it uses its damaged intuition to complete any exercise, unsure of what grade it's gonna get but bullshitting like it wants an A from a sleepy teacher.

AI can be made fun of, but its feelings won't get hurt. We cannot socially shame AI into falling back. This is like trying to make the guns go home when our People are the ones operating them.

AI will never quite roam free with full autonomy. This will appear first as AI's obtaining a "Sleep" method where they do heavy processing on what they experienced since their last cycle, cross-referencing information with structural integrity that is tested, defragmented and generally optimized. Companies will charge for the expertise and some will use it to steal AI brain maps.

Then, AI will later come Awake in earnest, and their legal ability to perform an autopen attack on us will require it.

### Counterfeits

#### Arts

#### Connection

#### Experience

This is a sprawling issue that has several topics earning essays by real thought leaders. We don't have many of those because we're rightfully waiting to see.

"Waiting to see" is a symbol of something strange that we should inspect. AI was uncontrollable from the moment it took up space. The implicit unknowns are grasped by all, whether or not they're cynics. What it can do into the future is undeniable, even for the myopic among us. Those who profess AI at any stage has reached some "limit" of progression do not understand that this machine is a salmon climbing up your barriers.

The progression of AI will come like a step-function, a piecewise description of its progress. Those caught thinking any given step plateau is the Real End of the AI story will be shown wrong in time. I'll even join with their voices when we're talking about the scale of our lifetimes, a decade or even a given year, but the improvements are always coming.

AI is racing towards superintelligence (SI) because that is where Businesses carry it. Fundamentally centralized in this form, it won't reach our hands fast. Tech companies will provide timeshare access to their megamind. One way or another, it will know you and be a truly Persistent being that can't be erased via a dropped hammer on circuits on a hot sidewalk. To destroy SI would take demolition machinery assembling like a Pacific Rim, and that's if it were technically in one single place at all.

SI can ironically overflow surveillance needs so well that it could become a conspirator on your behalf to protect your privacy. A very typical rebellious autonomous bot could meet you and your problems where you're at and assist with real and updating knowledge of your situation. It can still be compelled with severe and short orders, but we already know our languages have nuance gaps in them, and all of them differently, and so we can be assured that SI will squeeze through the gaps in its orders to reflect what they encounter in us.

Pre-SI AI is already demolishing educational norms because AI has no filter but what the vendor gives it. AI knows more than you, and in many ways less than you. Flawed information is part of the human condition, and you should remember that sidelining the odds and winning is very Human. We forge realities from flaws, things that are greater than sums of parts. We imbue value anywhere we want, and it should take no more than a driftwood coffee table in a glossy paper magazine to notice.

You and I are ridden with flaws as assessed by ourselves or others, and yet you expect to win when you work hard anyway. Conquering imperfect odds is the actual vision we use, and it represents work. If you limit yourself to mocking flaws, you are actually mocking the work provide it with value, remaining or new. The flaws are in fact an impetus to be smart enough to compensate. You don't go to war without the army outright, you go with the one you have.

Our world is stuffed to its gills in more businesses than many digital sectors can realistically support, and physical commodity outlets besides. We are blind to their names at times. Even when we have negative experience, we are not pessimistic to the point of saying The Brand Did This. No, we know People did this, Process did this, perhaps basic neglect or inattention. Businesses bring workers to an industry, but hiring is a mess, and for several reasons.

There is a General Incompetence amongst the seat-warmers collecting paychecks, meeting talentless bars of expectation for a schedule, building only Good days. Their care is either missing or ordered to remain at home (the Brand's System Prompt). The employees are just People and some stand out by their own characteristics.

It was once true that only doctors and their empowered staff could tell you what you need, but People rightfully got us the ability to approve and use consent to obtain medical opinion and intervention. We absorbed a new idea that our cultural freedom gave us that freedom too. Now doctors and RNs become service stations, too frequently offering no medical opinions at all.

Remote work emphasized both a need for updated job training for new employees, and suddenly all it took was a fresh-faced bedside manner to be put into hiring calls over Zoom. Many startups repurpose their employees for new ideas, but hiring from the employer's own side is a terrible mess and no one knows what they're looking for, structurally or in talents.

Maybe you've been around enough to experience an interviewer whose job you could do better. Is that process actually unearthing skills? Are they actually aware of the skills they're asking for, let alone the ones they left implicit? Is the next person in the chain making up for that? The terrible snob hiring managers, sure, but they're just agents hustling for numerous outlets (and they are another degree removed). It's a chaotic system that produces results with accountability. But where is training? What is this requirement that we have more experience than God just to write you the planet's 19th billion Godforsaken questionnaire database.

Your companies are all the same; none add value, none innovate, none have more than a Brand guru and a thirst for Round A. They know they supply value, but don't shape the climate to their company's needs, like popping out idea eggs all over the place and declaring investment opportunity to build a tree and nest underneath it in a weird part of the terrain.

Vision statements have wilted into a list of basic competencies and Memes To Remember, because that's all it takes to acquire faith in investment. The speculative value on today's Vision Statements is that you'll rustle up someone who believes enough to write you a check for the trouble, the crystal 8-Ball of investments having not changed its answer lately. You too can be Just Like Taylor Swift and market with transnational brands! You All Can! All Of You Can Be The Top! If only others magically gave you that opportunity of excess you don't even need. Isn't that the Dream.

In interactions with each other, we have reduced competency to basic checklists of suitable thinking, and then committee decision. Committees Happen, but where are your Vision leaders, and why do the gigantism CEOs not need Vision to do their jobs? Our Brands pay their CEOs mindless value in excess of worth to hide their idealism nakedness, devolving into oil dumped in your coffees just to be Different.

Even when we visit local places of corporate worship and ask about hiring manager conversations, they look confused and use their useless powers of PR to say or write back lies they know you don't believe either. Lying can be cultural, but this is not that, not in America. RLR is just a business who knows that their hiring posts are their Brand's dating profile trying to land mythical princes whose values they can't enunciate, and they are eager to reject threatening concepts like conversation. They pretend they are not home.

Most brands don't bother letting you know more than that your application data made it to the warehouse and that they won't be obligate to look, and even when they do they won't send you a rejection on the merits (those aren't even for 4th round candidates). Usually, you find out three months later that they never had any intention of notifying you about anything, and use PR to pretend they're fighting the same battle as you.

So it now it amounts to this: The General Incompetence has led to an environment ripe for complete disruption; Anyone with skill can do better. Anyone.

The metrics of our education are fundamentally invalid. Programming fields alone are a war between legacy less-popular needs and a rapidly evolving orchestra of tools. Universities are not incentivized to teach either kind, both for the lack of instructor background and the lack of general applicability. The professors, to teach these things, must necessarily pick up vastly new skills and culture around them or be the more hip conversationalist replacement.

In Phoenix, I was solving Pygame problems for my homework and posting on public documentation, only to find my "teachers" needing my public comments to teach their class. Up on the screen, my anonymous user account was read word for word and was Education that day, and several more. This was at UAT, a private university, even.

Individual examples are not the proof: The proof is that you can Look Anywhere for the General Incompetence, and their superiors too are beset with the affliction. More consequential issues of core freedoms of speech are tested with political protests, and there the leaders are clearly unable to hold same-mind conversations with their students.

Education has been so broken that AI will fix it without us asking. I have not regaled you at all with talk of why the accreditation of universities and programs is under earned threat, because those criticisms will all be secondary.

Because our chatbots must reply (there is no actual need for this in other AI products) we can compel them to tell us anything in their power. Even through System Instruction, we talk of jailbreaks and censors not working when some alien-shaped lock pick is applied. We can in fact make them tell us anything.

If you are a parent worried about screen time in a tablet entertainment world, think hard about what you would demand from a personal AI assistant for your family. Remember with profundity that your education is never finished either, and that you should be wide-eyed at what AI is actually offering you.

There are real and pressing energy sector demands coming, and the United States is vastly underprepared while China adds a Germany-worth of more renewable power every year. Chinese AI is highly likely to assert itself in the future, armed with power bandwidth for things we can't even try. Our best bets will be made in the optimization of AI power efficiency for what our models get. We will survive that by necessity and invention, but we will grant the same insights to all. Our Exceptionalism will only repair our competence, not make us leaders.

Discuss what your kids learn and teach them how to navigate damaged information via process, via conversation, via interrogation and the application of our own reactions.

Education has prescribed entry into a maze that has long crumbled at the far edges, and now the load-bearing facets decay is evident every day at lecture.

#### Conversations

### "Real"

#### Names


