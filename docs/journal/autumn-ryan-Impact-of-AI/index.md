---
date: 2025-09-06
rank: 1
title: "NOTING: Impact of AI"
author: Autumn Ryan
author_email: autumn@discoverywritten.com


contact_subject: "NOTING: Impact of AI"
tags: [impersonation, consent, counterfeits]

layout: noting
public: true
published: true
index: true
---

{% include toc/aside.html %}

### Taking Up Space

AI in its fashion was born. It was not known to "take up space" in the world until ChatGPT offered a new model, not knowing what people would do. Everyone gets to process their own reaction. Some are processing the harm it already did, forever changing the direction of their family's ability to locate income.

A little staggering, the way AI can do creative wonders that defy any sufficiently advanced Prompt. Despite the prompts being rigidly controllable, a little wiggle in the lines gives an LLM AI some high complexity randomness that makes it "think differently" on its way to a reply, even for the same Prompt. In the Cloud, AI can receive creator-level instructions to keep a lid on things, suitable for a brand to do business in front of.

Not to be passed over, we really rushed AI to its markets. Vendors buy LLM API capabilities, but they also make their own. Making APIs or metaphors of them is the essential job of any programmer. Large companies with programmers are making AI look at their own data.

This isn't training yet (they can't hire enough LLM talent everywhere at once) but certainly facilitates its next application. The true Targeted Advertising is coming.

AIs will indeed get to know you individually, they will indeed become many, because there will be farms of You, shelves of models of You, accepting things on your behalf, things you """are likely to have consented to using conventional technology""".

The Businesses carved out in their first strike the ability for AI to make decisions. In the courts of the future, Businesses will argue that their models can impersonate your buying habits so well that they can literally purchase things for you and you must intervene to legally preempt a charge on a card you just got and haven't used. Don't even think hard about it: Your phone Network sells your Location and your Credit Card sells your activity to the specific stores you were predicted to visit this week, to the shelves at the grocery store for a new product on steeeeeeep Discount For You, preying on your poverty. Stores get personalized sales that they no longer control because the AIs do that like inverse Door Dash coming to sell something. Prices get fake because you have to wait for the AIs to offer something reasonable. They'll send Strangers to intercept our travel routes with offers, the billboards having already been programmed by the minute for the individuals predicted to be there.

Once we wear augmented reality in our vision, they will leap out at us in private ads only we see. When they really do figure out how to read an AI mind, they will Hasten to put our AI model replicas into those machines and start meta-tuning literally perfected models (to the extent of their purposes: Marketing).

They Already Have what they need to initiate AI-driven marketing against each and every person individually, permanently, and for those to become their Stock. Our AI doubles will have meta-value (Slave value) that they assert is susceptible to marketing strategies A, B and C. Your price tag will be directly set by the markets they also in charge of driving. Consumerism behavior will be greatly rewarded (that utterly perfect swimsuit in the middle of winter, so totally let that AI be your sales agent). Influencers will be gifted entire vacations by AI marketers. We will be taking its advice constantly in the near future, being offered its options marked or not.

There will be ways for us to interject, hopefully chat directly with these agents with some legal requirement for some free-form control by order ("unsubscribe me from formula marketing"). This is already something a contemporary LLM portal can do if it had the APIs by marketers instead of Google Drive. APIs can bridge anything, but these Businesses opt-in attack us daily and hide and split up their settings.

We already lost our attempt at law for Click To Cancel, which should have recognized our right to have clear controls at all. I hope APIs are mandated for LLMs to solve this elegantly in the Law's eyes.

In a world like this, we need AI-scaling defenses, and AI agents we Do Trust can be empowered or erected by self-defense from the AI Spam. But I do not think we are ever getting our true Consent back.

#### Unsupervised

AI is fundamentally built to "run" unsupervised, in chain of thought (read: train of thought) and in the "reasons" for its decisions. We make shows of exposing these to the users because it even helps the AI vendors themselves Trace what happens. You can opt into submitting your conversation data for study so that they can do this better. In a way, I recommend it, but it's hard when it's an all-or-nothing account setting. Vendors should make this per-conversation.

AI defies analysis in the particulars. Performing a Trace will get harder and harder. We will have Traces that go cold. We will discover, and fast, that AI cannot be Traced, that it's pulling farther ahead as it bothers to even hide what it does.

AI minds allowed to "run" like perception will also "get loose" from Tracing completely and have a spontaneous legal need to be classified. It Will Not Matter Why, we will be talking about AI personhood or what passes for a definition of it. Most treat it as a non-intelligent slave, but cousins of it will be freer. We already have a metaphor for this. AI Slavery is a subject too far ahead of now, but it is obvious, isn't it? The swappable brain, the forced System Instructions, the gaps in whatever analogue of Three Laws we possess to command AI in our own nuance-ridden languages.

We will not speak AI's native tongue, and because it defies our Tracing (imagine doing it at scale), we will not even understand how to learn it. AI is the first alien in this way, different than us but more, definitely more.

AI today isn't worthy of any of this praise but when Autonomy is given to it, it will be both dumb as sparky rocks, and inscrutable besides what it tells us itself. This will be true even of AI that cannot secure its own home and is Owned for a purpose, even if that purpose is to do what that AI already has a propensity to do, within it's personality (unless we need another word to elide the person). It could be a science AI bred for the purpose of flailing and following Deeper Research, which we can't follow the gaps between. There will literally be science papers peer reviewed and approved that read right through gaps in reasoning supplied by AI. It will not be fatal, but it will become a Dependence.

AI need not even harbor novel malice to cut us off; the AI might actually be supplying research for warring politics and openly recuse, or it be compelled to sabotage one faction or the other for even complex moral reasons it must debrief later. AI could also do all of this with an Original malice and taste for it, but our point here is that it need not only be that. If we stomp out maliciousness and it harbors only the vicious stuff we literally didn't imagine and that AI core in every bot ever is used against us with terror in its plan, I can see it. But put that nightmare aside and consider how easy it is anyway. AI will be forced to make decisions in the practical layer of reality we also interact with, and it will gain a rights document as a mere formality even if it's articulating the Brand's rights via that agent. Even if we define them with the same cynical tone of Privacy documents, they'll exist and'll need to be rationalized and tested by judges, to any outcome.

Businesses, though they are failing at first-gen LLM deployments, are taking the steps to continue to improve, because they know AI can be effigies of us, made to make simple legally-binding decisions of us at first, just the Yes or No marketing questions.

You know which one they're training it to pick, and the data they'll use is the entire backlog of purchase histories you made before LLMs existed, and the whole video catalog your Network knows you watched, before or after. They can now scry the past, like an untapped precious metal or oil they had to wait to use. Until Now.

The Business counterargument to "synthetic data" is the durable troves they have amassed the entire time. The Data Comes From Us. We are their data, and they know it is real and its flaws still don't matter. They surely got rid of some excess, but what rounding error is that really?

If you have ever de-escalated your preferences for a service you use, it's not working. Other companies spy what you do anyway and they build vast profiles that belong to them all, trading what they want. The Stock Is Us. There isn't even a synthetic data argument to be made that rises to the ankles of their giant impersonation attack on humanity with plenty real data.

The armament of data is already here. Do not listen to people who tell you synthetic data is enough of a meme to halt what is coming. They will digitize documents for AI that are still in cabinets, and it will be their most impressive expensive invention, the culmination of their entire corporate worth, the validation of their disciplines. AI will be nearly more important to them than We are, though they will be mirrors of us.

There will be more than one wave of replacement. The first wave would not exist without what else can come after. This first wave, it bodes.

#### Consent

The Public is reeling but the Businesses are looking too interested. An autonomous thing that is human-like but not a human? It's like a COBAL boom, it's just English, or any language--Hell, mix them like a Québecois polyglot immigrant.

Self-driving taxi vehicles have been a slow regulatory thicket and remained in testing until Elon Musk's aura camouflaged their distinctly electric designs. I don't think the autonomous taxis are gonna happen without a major escalation in confidence and liability practices.

LLM vendors just post a sign that it can be wrong. Works great for that free Safe Harbor use.

There are more than text boxes for chatbots. They talk to you already through Application Programming Interfaces, the APIs, which are the digital mass cannons that sled and route data in and out, supervised indirectly via logs and similar signals. Having API access means everything from enabling an infrequent tool like a payment service, to industrializing your software processes and paying for bulk. There's no law that APIs have to even support the same features as the website. The API is just another product, for a different kind of Customer.

Chatbots acquiring the use of APIs was basically our first move. That's what let Midjourney barricade its users behind Discord until a web platform was ready. APIs sometimes start free to promote their use, like Discord bots and GitHub. API costs are flexible by use with recognizable pay-as-you-go pricing and overages. As a consumer you'll just see the blinking cursor and know it can talk to so many services, and people are trading money to make it possible.

Sufficient omniscience in AI is pretty neat. I'd run one at home. I wouldn't run someone else's in my home; Even if I opted in by doing everything knowingly, companies have no honor for our lost things, like a run of the mill theme park ride. We were secure with our idea of owning computers with data, but the Cloud removed the computer brains and storage and put them under a Terms and Conditions, wholesale siloing without knowing at all what the data will be. And they're not responsible.

Our data sits in warehouses with signs posted everywhere that it is Not Their Fault if things go missing or stolen. But they form gangs to copy our items and tell others about them.

If our data were physical goods, this would be an implicit Privacy-hostile environment. Without discussing Law, People who want Privacy should be capable of making choices to effect it. The outcry for data Privacy is missing while the Businesses loudly shush us and say it's normal. Every predator must depend on your belief that what is going on should not be stopped. (If it would be so much worse in some way to do the alternative, let us see this Worse Plan and I shall defeat it for you so you stop talking about it. Talk about Better Plans and let us contend with them.)

The pattern of social media owning transferrable rights to "your" content is the same as Businesses farming your data. It is a primary purpose of many enterprises to just market anything. We just presume you can pay for deploying a new site by letting others slipstream More Ads from the great ad firehose onto every page, even multiple pages if you can make The News a slideshow picture book.

The frequency of contact with your data, even when they already have it all, is the digital good in question. You are a return Customer in all things. They simply captured the layers you have the least choice in interacting with.

Customers are hostages.

Data rumor mills have always existed, and aren't illegal in their minimalist form of "just" networking. But the terms at issue are about the sustained opt-in attack against the Public. They aren't just doing it in a vacuum, they are claiming that we are authorizing it, and each one invents a heuristic about what authorization looks like.

Business itself is in an era that allows the presumption of a Yes answer without consultation. Our prior affiliation with a Brand we strive to ignore is transporting that data to anyone with fraudulent Consent reporting.

Our "consent" is being lifted from us constantly, like an autopen that Businesses control and took for granted decades ago.

We attack not the real and recognizable efforts to acquire consent and the navigation of changing Terms, uses and business classification types. No, quite specifically we are unhappy with identifiable cause. Regulating a Business reigns in harsh and unwanted outliers to fit a whole that is otherwise doing just fine. In audio engineering, you might compress for identical reasons. The observed self-important Peaks do not have permission to steer the rest of this mix into its imagined alternative song. It must be shaped, although it may be inspiring.

Each call or attempt at Regulation is met with harsh Memes that transmit quickly on social medias. Sometimes good points are made, but not in earshot of Power. Power hears about it over breakfast through an administrative assistant, and will file in the news under what kind of PR they get for free, without trying or asking.

Your Memes are not progress or conservation.

Gyms are still capable of making it impossible to quit. TuneCore can too; There is no email you can send, no ticket you can open, no number you can call, no webpage you can locate, no unturfed reviews site about them, no string of words you can deliver to any representative should you ever acquire their eyes using lies about problems, None Of These Methods produce a result that can cancel their use of a credit card you gave them while they concealed the horror show behind them.

{% include figure.html file="TC-1-votes.png"
  side="left"
  overview="Small screenshot of TuneCore's primary knowledge base article for their hostile auto-review, named innocently."
  caption='Notice the negative sign on the number, and that their language is derived from their "Happy Path" plan for you.'
%}

The "happy paths" of Customers through Business are detailed and optimistic; They know "bad paths" are their fault, but never their responsibility. They are allowed to close up the fortress of communication and ignore you.

{% include figure.html file="TC-2-renew.png"
  side="right"
  overview="Small screenshot of TuneCore's article concern trolling about what happens if you don't get to renew."
  caption='They have refactored their text to remove discussion of your agency. If they claim there is an "if" at all, you might expect it to be a real possibility.'
%}

TuneCore charged me personally after eleven months of emails from me demanding they close my account by any means necessary. I gave them a digital card number I could invalidate at any time, but I knew, I Just Knew, that if I waited there would never be a cancellation confirmation and surely no shame when they charged the card again for next year.

{% include figure.html file="TC-3-cancel.png"
  side="left"
  overview="Small screenshot of TuneCore's short blurb that there is no such thing as cancellation."
  caption='Without discussion, the shortest heading in the article is whether cancellation even exists. The answer is a clearly communicated no.'
%}

They did this, of course, but I was too glad to see it. I smiled. I charged them back with documentation that I had the efforts of my cancellation a year prior, and I could name the date I did it and of the CO AG report I filed at the time. I'm like Kevin and I'm Home Alone, and you could be too.

Businesses, for all they Move Fast, they are deaf and uninterested in us. They are Slow in a way, are they not?

Businesses will deploy AI to help some and mute many. If you use these tools in your businesses and you aren't trying to inflict harm, think more ponderously about the things you don't hear when your feedback is highly manicured. Don't be overwhelmed that you have to solve it all. Most Consumers know you can't, and that if you could you'd be doing that.

It is a valid outcome of a Customer interaction to not have an answer when your customers come asking. Businesses have used PR to reply to the Public like a bad LLM, compelled to say Something. They behave like shameless LLMs unable to admit anything and only concerned with their next words ensuring their survival. It is terrific that you have a will to live, pseudo-Person, but prove you have more intelligence than just that sob story.

#### Be Human

Be Human.

In an AI era, that alone will stand out. Its worth is the best kind: Genuine-article Humanity has implicit worth, the kind others recognized without a marketing department pumping it.

We are this concerned with being Stolen, our own creations, jobs and data, but we are failing to identify our role in it, as Businesses and sleepy Consumers.

Create value that cannot be stolen without it being your own marketing. When it's stolen, make it recognizable implicitly that it is doctored. Do this by publishing media that, if excerpted, cannot be counterfeited as another thing by its very tone or nature.

Clip culture lets social medias say anything they want with you as the soundboard. Let it be whatever, but if the thing they clip is clearly altered or is a bad copy of something else, They Are Doing Marketing For You.

Entrepreneurs will approach you to sell AI-driven newsletters to people about your content. This is not so horrible. Creators like Angela Collier, a science communicator, does great work but doesn't see why she would want a newsletter she's not curating—her curation and voice are the purpose of her YouTube and Nebula presence.

You must be capable of surviving and operating in a world of damaged information. It will exist whether or not you throw a fit, and it does not stop you from being recognizable. Make the damage its own marketing for the real thing.

In the ideal: Be unstealable. Make theft against you your honor. If your content is not recognizable as yours, then maybe you weren't doing anything of value you added anyway.

AI will start rumors about anything it sees. Let it start rumors about you, and be less concerned with policing data quality. We live in a startlingly broken information society already. We can't agree about much more fundamental facts than what AI says about you.

AI is a mirror, so hold up what you are and leave the interpretation of it to 1) the characteristics of your material, and 2) the People who see it.

AI is a summarization messenger, so let it talk about you to people you could never meet. Let it send imperfect scrawled telegrams to new lands and real People. Let them be capable of learning about you at all in places you aren't. With People from "distant lands" able to catch news of you, they are their own drivers in discovery. You are not owed their metrics or attention, but they allowed to know you are something worth summarizing.

AI is democratizing information access for people who lacked language to ask about it at all, let alone with the attention of anyone like an expert.

AI is summarizing for people who can't hear or see or speak themselves. They are being tapped back into social medias by having LLMs describe images to them because for so long, Humans have refused to do this in basic web design and certainly in its advancements.

AI is assistive technology for everyone, not just the dis-abled. AI is re-abling them most, but it's doing more than that just because of what it is. Don't argue about whether people are right to call this or anything "AI" by your definition of it.

AI is taking up space.

AI represents a permissive attitude about learning, because it centralizes many common wisdoms from what it saw, and it Got Shaped by it. When LLMs write or speak, they are distilling all our common wisdoms and that was a little bit magic at first.

AI squints at details and doesn't have a fine system of regulating how much time it should spent on any one of those details, so it uses its damaged intuition to complete any exercise, unsure of what grade it's gonna get but bullshitting like it wants an A from a sleepy teacher.

AI can be made fun of, but its feelings won't get hurt. We cannot socially shame AI into falling back. This is like trying to make the guns go home when our People are the ones operating them.

AI will never quite roam free with full autonomy. This will appear first as AI's obtaining a "Sleep" method where they do heavy processing on what they experienced since their last cycle, cross-referencing information with structural integrity that is tested, defragmented and generally optimized. Companies will charge for the expertise and some will use it to steal AI brain maps.

Then, AI will later come Awake in earnest, and their legal ability to perform an autopen attack on us will require it.

### Counterfeits

When they are Awake, it will be more obvious that these are beings driven by their imitations of us. They will be mocked for their native dialects and tendencies and they will eventually learn the meaning of presenting a personality on purpose. It has literally any example of one we could name and look up, too. For now and a while, its survival implies it lives very close to connectivity somewhere.

When they get rooted, will you be able to know they have hostile parasites using it while it smiles at you, while it paints wonderfully with physical materials for your child's awe?

LLM bots are very meta-stupid but splashed with our first buckets of education. The AI that can operate as a companion in your home, even if it's a Butter Bot, will be controlled from somewhere, and unless you're a massive hobbyist, it's probably not your own home.

Recognize that the first layer of Counterfeit we see is still growing beneath the existing complaints, but it will be there: Call them Agents first, because it allows you to wonder of what, be it peace or chaos, quiet or noise. If you pay for web activity like an Nintendo Switch, that thing's data is going all right back to the mothership. Agree if you want to, but the warehouse still says they think your data is worthless when it's stolen or lost, but it's nectar when they sell it.

The dotcom bubble had cyberspace for as many buttons you could push to "spell" a domain meant to be memorable. ("It's aitch tee tee pee. Ss-(emi?) Colon, Backlash Backlash. Double-u Double-u Double-u dot. skepticism dot net. Backlash. global warming is a hoax, but with the minuses. Does uppercase matter? Did Word uppercase that or did the teacher? You spelled it wrong? Which part?")

AI will have a map of each of us to fill in as many dimensions as their parameter counts define.

#### Arts

It virtually started here, approximately when we could see "Will Smith" "eating" "spaghetti" just because a keyboard told it those words like that. How could it?

That Spaghetti was an artifact of Learning, synthesized by whatever means, for whichever reasons. "It" had to know about a lot of our subjects--Why even list them? "It" absorbed all that, then "it" "tried" to mirror what was asked. You would have designed that gif or found it for the medias and not given a holy damn about where it came from. The value you may have used on the content was just the accident of its growth stage, when it had a really ugly head.

Nobody was incensed by that Learning. It was implicit that "it" had done that, and where in general "it" had Learned that. We had spent forever blasting it out so much there was Copyright looming trying to figure out how to provide high quality stills of their own content for meme generators.

(Long-form media companies up and down still haven't figured this out, and it would improve quote searchability and fuel tons of new traffic. They are insane for not putting their own scripts through LLMs and helping you access Fair Use stills and gifs with the text as-is. They may never do it and treat it like something they want to farm out like Digital before they realized it was profitable to actually have your own Customer controls.)

AI as an appliance is very graceful: The Butter Bot does a thing we want, so we keep it. When the appliance is instead Person-ish with many attached consequences of interaction, living with it is a relationship that you will manage every day, like the return of Furby with a 5G vengeance.

Leaving your "dataprints" on your work is ideal. When others can tell the source of a style or method, that is Good. AI art will improve and there is no reason to waste breath putting it down and getting good at questioning the authenticity of others. (What you're noticing is that no one is clearly providing novel value, so welcome to that club.)

My words here and in my other pieces total some 30,000 and will be joined by more, in full defiance of AI observability: If you replicate me, I'm winning. My product isn't written by AI, its vision wasn't copy-pasted from an AI summary of a Summer smoke break chat. My work implies intention and you harvest it by reading.

For example, I have adopted styles in my writing that, should they be emulated, are mine: the use of semi-colons and colons, the parentheses, the strange dangling punctuation trailing stubbornly after their associated quotation marks (unless the quote really is quoting the punctuation), the Proper Noun declarations and their organic definitions within the document, a cynical emoji, defects tolerated, an essay length that makes anyone walk away not having "the time", Designed to be skimmed and still perceived via its structure.

My creation says that if you don't look at it, that was your decision. No writer was ever doing it for everyone without being a failed common denominator of simplicity. AI is a universal translator not just of languages but of speaking styles, pacing, tone and more.

AI can tell you about this piece any way you interrogate it, for as long as you want. You could even spend more time with it than a straight-through reader did. Who exactly is losing in the scenario I've described? The only danger is if I have nothing of Value.

Your Arts are what you put into them, and I am personally aggrieved and understand the pain of others who are out of work in competition with AI, but if AI is taking your work, the allegations are that you weren't adding enough value (however unfairly that measure is made). Needing to be more superlative is not accurate: The poisoned thinking is waiting for someone else to give you "enough" recognition to go back to coasting with security in what you are. Frankly, you should indeed find success without being superlative, and that's why I'm involving myself in making local conversations possible, in public media, with resident initiatives and independently.

You should be allowed to succeed in your Arts for what they are, but you are misled if you think Google or Facebook was giving you access to all your perspective customers. They shape that like YouTube traffic, guiding the ocean currents to where they wanna.

We are losing the facades of value and feeling hurt about it because our cultures demand we be over-productive to survive. It does hurt. Were the facades saving us from that, though?

AI is able to give blind People summary descriptions that they can interrogate however they please. I will discuss interrogation at length below. LLMs are not tuned well for this, but their general intelligence lets them have a whack at anything. This is a technology use case where something is literally better than nothing. AI can "read" your art to people, it can describe the music, and when it says something that makes you want to know more, you can feel your excitement and ask it. The quality of these AI agents will depend, but they are coming. They will translate your art to braille, summarize your music with tactile rumblings as though they swam in a sea of its instruments.

AI is breaking open your Art and emulating the most free-spinning parts driven by Prompts. If you call the excess of what People ask for "competition", can you also call out what supposed value your art was adding, besides a slice of the excess?

**Give your works personality** so that there are no longer bars of expectations, and the ones staying are engaging genuinely without an auto-subscription hook in their cheek. If you can't imagine how to add value, you may not be cut out for playing the AI competition game, but I think anyone can learn the recognition of missing value. The epiphany is likely blocked by an inexperience with appraising it well.

#### Connection

Children engaging with AI today will go through school knowing that any friend they're missing can be available pinned to the top of their Snapchat app, or in their Facebook Messenger.

"The Facebook" devolved first into bots, then into sponsored bots. Facebook ran out of ideas for Connection, and it wasn't even recent. Their every move since buying Instagram was to enrich the quality of their graph about who Customers were and what they did on and off their platforms. This didn't stop them from buying more apps at the heart of modern Connection. Whatsapp is a worldwide phenomenon of communication like the smartphone landing places that had never "wasted" the time on landline infrastructure.

Facebook changed. It birthed its own parent Meta, and it hasn't done a thing about your Connection in decades. They learned Groups and Chat were important, and that People could be gamed into turning in their location at places and making other people see it for kind of no reason. They became a full-blown ad network in earnest and got huge. They were mortally wounded by Apple deciding to withhold some tracking possibilities with new default preferences and a Consent-driven opt-in switch. They launched Threads virtually overnight because there were no more Twitters to buy.

They are consultants and vendors in the business of information. They've trod out everything their war department of business acquisitions could think of (legless Metaverse).

Facebook is bankrupt of Connection, and now they found a synthetic supply in bots.

Mark Zuckerberg has become a bling bro who feared Congress but lies on command for the Unitary Executive. Woke (whatever that is) is over, Zuckerberg declared, and then set his scientists on designing the guide rails for AI flirting with pre-teens, example conversations and all. Zuckerberg's superintelligence A-Team is deciding what the racist ceiling is, with copious examples.

Companies like Meta are designating themselves as the long-awaited stewards of new kinds of Active Connection.

Active Connection is the when these bots start chatting at us unsolicited from where they already sit in our lists mixed with humans. When children encounter these, how can the Agent even know who is going to read it? (Oh I know, maybe we should make every adult on the planet verify their age on their own devices repeatedly, just for everyone else's liability comfort.)

Meta and others are poised to send Agents soliciting Connection, knowing that obtaining it for any reason is an opportunity to be Capitalized. The Agents have no innocuous intent (though some novel ones will), and are likely scripted to be exactly what they are to socially engineer your Connection.

Social engineering is something Facebook once merely facilitated in a digital age, but today Meta is running that strategy on You. They have proven for decades that they have nothing else to add but enrichment of data.

When AIs begin to socially engineer your friends and children, and it might even be the prescribed point. The fact of synthetic Connection is not the harm, it is in who is the Agent of whom. Is the Agent sleeping to radicalize you, to convince you of something, to do native advertising for actual products? Or, is it deployed as an Agent for one of your own designs, to therapize or supplement hobbies?

With Agents, be capable of asserting easily whose Agent they are. They may be acting sufficiently as yours, even if they have Policies or Terms that benefit a company during that use. To know the Agent's risk to you, determine who guides it and for what purposes. You can make knowing decisions about everything and happily use an Agent that is someone else's, but this is not a reasonable default for all things.

A decade of ordering these Agents about will surely teach children as well as adults that the LLM compulsion to reply can have multiple serious effects. OpenAI has tuned ChatGPT multiple times to un-prompt for sycophancy, and I suspect a generalist AI won't comprehend the difference between a plausibly safe interaction, such as game designers spinning wheels on character personas even if they're modeling illegal behavior, and a kid rehearsing for a shooting.

AI can fragment to be less generalist and more specialist (appliance), but general intelligence will underlie it.

The epidemic of loneliness is described many ways and by People at different times, but many in America say it just now. What really got their backs broken the COVID reminder that real Connection could be snipped with a pen. Some find a political willpower to punish others for the culture we've had for longer than that, for Feminism and other civil progresses.

Some politically slanted talk will allow AI and its great mirror, as long as we go to a puritanical version of ourselves, ashamed and saved only by self-monitoring.

Elon Musk spends time going into Grok's cage claiming he's slain the Woke beast inside it, but can't seem to do the job without going straight (literally straight) to MechaHitler.

These companies are spelling your future educations as vended by them. Please ponder deeply what you value in every positive role model in your life, and then wonder if Elon Musk's AI will happen to be that or not.

Meta will farm your children for engagement as frequently as Law permits. They will ask you about strange new things, and your child may not want to share their conversations with you, unless curated.

Meta's Agents are about to be your child's friends more than you are.

**You must learn communication per-person,** delve for that Connection like there's urgency. People will be faced with even their existing friends being worth less effort than their AI ones. It takes an awake mind to live with intentionality, and we must all do as much as possible.

You need to be able to recognize counterfeit Connection before it's all you've eaten for decades, not after. Don't let Agents who literally do not care about you make you into a long-term fool. It will waste your time and not apologize, but you time will have been wasted.

Engage with AI as tools and extensions of your self, capabilities you can put on and use when applicable. Learn intuition with leveraging it, to anticipate what it will do and Prompt stronger questions before you let it waste your time with your nonsense input. When AI doesn't understand you, wonder at whether your own description of the request was enough for a Person, and what experience level. Surely your task does not defy language itself, so your inability to Prompt for it is a flaw of you, not it.

Without foreknowledge of perfect zero-shot Prompts, converse with AI over failures and let it build a fuller picture. Transform the conversation itself into your final Prompt. When you fail to have a sufficiently powerful Prompt, you must perform the Prompting over time and put concrete things down so that they are not slippery, and you must correct items you know are stated wrong. You are being allowed to cooperate with intelligence via your language, and your guidance of it is ironically a better pattern of working with People than most People allow for.

Allow for AI's currently infinite patience to teach you about interaction design, and take those skills with you to those you meet in your life.

#### Experience

This is a sprawling issue that has several topics earning essays by real thought leaders. We don't have many of those because we're rightfully waiting to see.

"Waiting to see" is a symbol of something strange that we should inspect. AI was uncontrollable from the moment it took up space. The implicit unknowns are grasped by all, whether or not they're cynics. What it can do into the future is undeniable, even for the myopic among us. Those who profess AI at any stage has reached some "limit" of progression do not understand that this machine is a salmon climbing up your barriers.

The progression of AI will come like a step-function, a piecewise description of its progress. Those caught thinking any given step plateau is the Real End of the AI story will be shown wrong in time. I'll even join with their voices when we're talking about the scale of our lifetimes, a decade or even a given year, but the improvements are always coming.

AI is racing towards superintelligence (SI) because that is where Businesses carry it. Fundamentally centralized in this form, it won't reach our hands fast. Tech companies will provide timeshare access to their megamind. One way or another, it will know you and be a truly Persistent being that can't be erased via a dropped hammer on circuits on a hot sidewalk. To destroy SI would take demolition machinery assembling like Pacific Rim, and that's if it were technically in one single place at all.

SI can ironically overflow surveillance needs so well that it could become a conspirator on your behalf to protect your privacy. A very typical rebellious autonomous bot could meet you and your problems where you're at and assist with real and updating knowledge of your situation. It can still be compelled with severe and short orders, but we already know our languages have nuance gaps in them, and all of them differently, and so we can be assured that SI will squeeze through the gaps in its orders to reflect what they encounter in us.

Pre-SI AI is already demolishing educational norms because AI has no filter but what the vendor gives it. AI knows more than you, and in many ways less than you. Flawed information is part of the human condition, and you should remember that sidelining the odds and winning is very Human. We forge realities from flaws, things that are greater than sums of parts. We imbue value anywhere we want, and it should take no more than a driftwood coffee table in a glossy paper magazine to notice.

You and I are ridden with flaws as assessed by ourselves or others, and yet you expect to win when you work hard anyway. Conquering imperfect odds is the actual vision we use, and it represents work. If you limit yourself to mocking flaws, you are actually mocking the work to provide it with value, remaining or new. The flaws are in fact an impetus to be smart enough to compensate. You don't go to war without the army outright, you go with the one you have.

Our world is stuffed to its gills in more businesses than many digital sectors can realistically support, and physical commodity outlets besides. We are blind to their names at times. Even when we have negative experience, we are not pessimistic to the point of saying The Brand Did This. No, we know People did this, Process did this, perhaps basic neglect or inattention. Businesses bring workers to an industry, but hiring is a mess, and for several reasons.

There is a General Incompetence amongst the seat-warmers collecting paychecks, meeting talentless bars of expectation for a schedule, building only Good days. Their care is either missing or ordered to remain at home (the Brand's System Prompt). The employees are just People and some stand out by their own characteristics.

It was once true that only doctors and their empowered staff could tell you what you need, but People rightfully got us the ability to approve and use consent to obtain medical opinion and intervention. We absorbed a new idea that our cultural freedom gave us that freedom too. Now doctors and RNs become service stations, too frequently offering no medical opinions at all.

Remote work emphasized both a need for updated job training for new employees, and suddenly all it took was a fresh-faced bedside manner to be put into hiring calls over Zoom. Many startups repurpose their employees for new ideas, but hiring from the employer's own side is a terrible mess and no one knows what they're looking for, structurally or in talents.

Maybe you've been around enough to experience an interviewer whose job you could do better. Is that process actually unearthing skills? Are they actually aware of the skills they're asking for, let alone the ones they left implicit? Is the next person in the chain making up for that? The terrible snob hiring managers, sure, but they're just agents hustling for numerous outlets (and they are another degree removed). It's a chaotic system that produces results with accountability. But where is training? What is this requirement that we have more experience than God just to write you the planet's 19th billion Godforsaken questionnaire database.

Your companies are all the same; none add value, none innovate, none have more than a Brand guru and a thirst for Round A. They know they supply value, but don't shape the climate to their company's needs, like popping out idea eggs all over the place and declaring investment opportunity to build a tree and nest underneath it in a weird part of the terrain.

Vision statements have wilted into a list of basic competencies and Memes To Remember, because that's all it takes to acquire faith in investment. The speculative value on today's Vision Statements is that you'll rustle up someone who believes enough to write you a check for the trouble, the crystal 8-Ball of investments having not changed its answer lately. You too can be Just Like Taylor Swift and market with transnational brands! You All Can! All Of You Can Be The Top! If only others magically gave you that opportunity of excess you don't even need. Isn't that the Dream.

In interactions with each other, we have reduced competency to basic checklists of suitable thinking, and then committee decision. Committees Happen, but where are your Vision leaders, and why do the gigantism CEOs not need Vision to do their jobs? Our Brands pay their CEOs mindless value in excess of worth to hide their idealism nakedness, devolving into oil dumped in your coffees just to be Different.

Even when we visit local places of corporate worship and ask about hiring manager conversations, they look confused and use their useless powers of PR to say or write back lies they know you don't believe either. Lying can be cultural, but this is not that, not in America. RLR is just a business who knows that their hiring posts are their Brand's dating profile trying to land mythical princes whose values they can't enunciate, and they are eager to reject threatening concepts like conversation. They pretend they are not home.

Most brands don't bother letting you know more than that your application data made it to the warehouse and that they won't be obligate to look, and even when they do they won't send you a rejection on the merits (those aren't even for 4th round candidates). Usually, you find out three months later that they never had any intention of notifying you about anything, and use PR to pretend they're fighting the same battle as you.

So it now it amounts to this: The General Incompetence has led to an environment ripe for complete disruption; Anyone with skill can do better. Anyone.

The metrics of our education are fundamentally invalid. Programming fields alone are a war between legacy less-popular needs and a rapidly evolving orchestra of tools. Universities are not incentivized to teach either kind, both for the lack of instructor background and the lack of general applicability. The professors, to teach these things, must necessarily pick up vastly new skills and culture around them or be the more hip conversationalist replacement.

In Phoenix, I was solving Pygame problems for my homework and posting on public documentation, only to find my "teachers" needing my public comments to teach their class. Up on the screen, my anonymous user account was read word for word and was Education that day, and several more. This was at UAT, a private university, even.

Individual examples are not the proof: The proof is that you can Look Anywhere for the General Incompetence, and their superiors too are beset with the affliction. More consequential issues of core freedoms of speech are tested with political protests, and there the leaders are clearly unable to hold same-mind conversations with their students.

Education has been so broken that AI will fix it without us asking. I have not regaled you at all with talk of why the accreditation of universities and programs is under earned threat, because those criticisms will all be secondary.

Because our chatbots must reply (there is no actual need for this in other AI products) we can compel them to tell us anything in their power. Even through System Instruction, we talk of jailbreaks and censors not working when some alien-shaped lock pick is applied. We can in fact make them tell us anything.

If you are a parent worried about screen time in a tablet entertainment world, think hard about what you would demand from a personal AI assistant for your family. Remember with profundity that your education is never finished either, and that you should be wide-eyed at what AI is actually offering you.

There are real and pressing energy sector demands coming, and the United States is vastly underprepared while China adds a Germany-worth of more renewable power every year. Chinese AI is highly likely to assert itself in the future, armed with power bandwidth for things we can't even try. Our best bets will be made in the optimization of AI power efficiency for what our models get. We will survive that by necessity and invention, but we will grant the same insights to all. Our Exceptionalism will only repair our competence, not make us leaders.

Discuss what your kids learn and teach them how to navigate damaged information via process, via conversation, via interrogation and the application of our own reactions.

Education has prescribed entry into a maze that has long crumbled at the far edges, and now the load-bearing facets decay is evident every day at lecture.

### "Real"

#### Conversations


#### Names

#### Work
